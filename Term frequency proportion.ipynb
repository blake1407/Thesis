{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "import math\n",
    "import warnings\n",
    "from collections import defaultdict, deque\n",
    "from functools import total_ordering\n",
    "from itertools import chain, islice\n",
    "from operator import itemgetter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus.reader import CorpusReader\n",
    "from nltk.internals import deprecated\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import binary_search_file as _binary_search_file\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from textblob import TextBlob\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjectives(word_list): # , , , hyponyms, antonyms, derivationally related forms, to expand a list of seed words\n",
    "    new = []\n",
    "    for text in word_list:\n",
    "        new.append(text)\n",
    "        for syn in wordnet.synsets(text):\n",
    "            also_sees = syn.also_sees() # see also\n",
    "            if len(also_sees) > 0:\n",
    "                for seealso in also_sees:\n",
    "                    if seealso.pos() in [\"a\", \"s\", \"r\"]:\n",
    "                        word = seealso.name().split(\".\")[0]\n",
    "                        new.append(word)\n",
    "            similar_tos = syn.similar_tos() # similar\n",
    "            if len(similar_tos) > 0:\n",
    "                for similar in similar_tos:\n",
    "                    if similar.pos() in [\"a\", \"s\", \"r\"]:\n",
    "                        word = similar.name().split(\".\")[0]\n",
    "                        new.append(word)\n",
    "            attributes = syn.attributes() # attributes\n",
    "            if len(attributes) > 0:\n",
    "                for attribute in attributes:\n",
    "                    if attribute.pos() in [\"a\", \"s\", \"r\"]:\n",
    "                        word = attribute.name().split(\".\")[0]\n",
    "    for word in new:\n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "        if lemma not in new:\n",
    "            new.append(lemma)\n",
    "    final = []\n",
    "    for word in new:\n",
    "        if word not in final:\n",
    "            final.append(word)\n",
    "    return final\n",
    "\n",
    "\n",
    "def get_positive(word_list):\n",
    "    new = []\n",
    "    for text in word_list:\n",
    "        analysis = TextBlob(text)\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            new.append(text)\n",
    "    return new\n",
    "\n",
    "def get_negative(word_list):\n",
    "    new = []\n",
    "    for text in word_list:\n",
    "        analysis = TextBlob(text)\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity < 0:\n",
    "            new.append(text)\n",
    "    return new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"corpus_full.json\")\n",
    "corpora = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"stereotypes.json\")\n",
    "stereotypes = json.load(f)\n",
    "f.close()\n",
    "\n",
    "df_nyt = pd.read_csv(\"df_nyt.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term_frequency = {}\n",
    "\n",
    "# for day, corp in corpora.items():\n",
    "#     date = day[9:]\n",
    "#     term_frequency[date] = {}\n",
    "#     for word in corp['corpus']:\n",
    "#         if word not in term_frequency[date].keys():\n",
    "#             term_frequency[date][word] = 1\n",
    "#         else:\n",
    "#             term_frequency[date][word] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stereotypical_tf = {}\n",
    "\n",
    "# for day, freq in term_frequency.items():\n",
    "#     stereotypical_tf[day] = {}\n",
    "#     stereotypical_tf[day][\"Warm\"] = {}\n",
    "#     stereotypical_tf[day][\"Cold\"] = {}\n",
    "#     stereotypical_tf[day][\"Competent\"] = {}\n",
    "#     stereotypical_tf[day][\"Incompetent\"] = {}\n",
    "#     stereotypical_tf[day][\"Foreign\"] = {}\n",
    "#     stereotypical_tf[day][\"Diseased\"] = {}\n",
    "#     for word, prop in freq.items():\n",
    "#         if word in stereotypes['Warm']:\n",
    "#             stereotypical_tf[day][\"Warm\"][word] = prop\n",
    "#         if word in stereotypes['Cold']:\n",
    "#             stereotypical_tf[day][\"Cold\"][word] = prop\n",
    "#         if word in stereotypes['Competent']:\n",
    "#             stereotypical_tf[day][\"Competent\"][word] = prop\n",
    "#         if word in stereotypes['Incompetent']:\n",
    "#             stereotypical_tf[day][\"Incompetent\"][word] = prop\n",
    "#         if word in stereotypes['Foreign']:\n",
    "#             stereotypical_tf[day][\"Foreign\"][word] = prop\n",
    "#         if word in stereotypes['Diseased']:\n",
    "#             stereotypical_tf[day][\"Diseased\"][word] = prop\n",
    "\n",
    "# stereotype_tf = pd.DataFrame.from_dict({(i,j,k): stereotypical_tf[i][j][k]\n",
    "#                                         for i in stereotypical_tf.keys()\n",
    "#                                         for j in stereotypical_tf[i].keys()\n",
    "#                                         for k in stereotypical_tf[i][j].keys()},\n",
    "#                                        orient='index')\n",
    "# stereotype_tf = stereotype_tf.reset_index()\n",
    "# split_df = pd.DataFrame(stereotype_tf['index'].tolist(), columns=['date', 'category', 'word'])\n",
    "# stereotype_tf = pd.concat([stereotype_tf, split_df], axis=1)\n",
    "\n",
    "# stereotype_tf.columns = [\"index\", \"frequency\", \"date\", \"category\", \"word\"]\n",
    "# stereotype_tf = stereotype_tf[[\"date\", \"category\", \"word\", \"frequency\"]]\n",
    "# stereotype_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df = pd.merge(stereotype_tf, df_nyt, on=\"date\")\n",
    "# full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df.to_csv(\"df_tf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_proportion = {}\n",
    "\n",
    "for day, corp in corpora.items():\n",
    "    date = day[9:]\n",
    "    term_proportion[date] = {}\n",
    "    corp_total = 0\n",
    "    for word in corp['corpus']:\n",
    "        corp_total += 1\n",
    "        if word not in term_proportion[date].keys():\n",
    "            term_proportion[date][word] = 1\n",
    "        else:\n",
    "            term_proportion[date][word] += 1\n",
    "    \n",
    "    for word in term_proportion[date].keys():\n",
    "        term_proportion[date][word] = term_proportion[date][word]/corp_total\n",
    "\n",
    "\"\"\"\n",
    "Before corpus of each person, see how many words fit in the dictionary (stereotypes.json) - or related words to it.\n",
    "Stereotypes dictionary generation: get all the word listed under a category (e.g., warm) -> get anotonym in under the opposite category (e.g., cold) -> get synonyms of the antonyms (related words) -> select all unique items (there will be overlap) - maximum diligence\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereotypical_tp = {}\n",
    "\n",
    "for day, freq in term_proportion.items():\n",
    "    stereotypical_tp[day] = {}\n",
    "    stereotypical_tp[day][\"Warm\"] = {}\n",
    "    stereotypical_tp[day][\"Cold\"] = {}\n",
    "    stereotypical_tp[day][\"Competent\"] = {}\n",
    "    stereotypical_tp[day][\"Incompetent\"] = {}\n",
    "    stereotypical_tp[day][\"Foreign\"] = {}\n",
    "    stereotypical_tp[day][\"Diseased\"] = {}\n",
    "    for word, prop in freq.items():\n",
    "        if word in stereotypes['Warm']:\n",
    "            stereotypical_tp[day][\"Warm\"][word] = prop\n",
    "        if word in stereotypes['Cold']:\n",
    "            stereotypical_tp[day][\"Cold\"][word] = prop\n",
    "        if word in stereotypes['Competent']:\n",
    "            stereotypical_tp[day][\"Competent\"][word] = prop\n",
    "        if word in stereotypes['Incompetent']:\n",
    "            stereotypical_tp[day][\"Incompetent\"][word] = prop\n",
    "        if word in stereotypes['Foreign']:\n",
    "            stereotypical_tp[day][\"Foreign\"][word] = prop\n",
    "        if word in stereotypes['Diseased']:\n",
    "            stereotypical_tp[day][\"Diseased\"][word] = prop\n",
    "\n",
    "stereotype_tp = pd.DataFrame.from_dict({(i,j,k): stereotypical_tp[i][j][k]\n",
    "                                        for i in stereotypical_tp.keys()\n",
    "                                        for j in stereotypical_tp[i].keys()\n",
    "                                        for k in stereotypical_tp[i][j].keys()},\n",
    "                                       orient='index')\n",
    "stereotype_tp = stereotype_tp.reset_index()\n",
    "split_df = pd.DataFrame(stereotype_tp['index'].tolist(), columns=['date', 'category', 'word'])\n",
    "stereotype_tp = pd.concat([stereotype_tp, split_df], axis=1)\n",
    "\n",
    "stereotype_tp.columns = [\"index\", \"proportion\", \"date\", \"category\", \"word\"]\n",
    "stereotype_tp = stereotype_tp[[\"date\", \"category\", \"word\", \"proportion\"]]\n",
    "stereotype_tp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(stereotype_tp, df_nyt, on=\"date\")\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(\"df_tp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
