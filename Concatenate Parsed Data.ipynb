{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field  # Import field\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove tweets talking about the train derailment in East Palestine, OH\n",
    "def not_palestine_OH(text: str, window_size: int = 50) -> bool:\n",
    "    \"\"\"\n",
    "    Check if keywords appear near each other in text.\n",
    "    Returns True if at least two keywords are found within window_size words.\n",
    "    \"\"\"\n",
    "    keywords = [\"east palestine\", \"oh\", \"train\", \"derailment\", \"e. palestine\"]\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = text.split()\n",
    "    for i in range(len(words)):\n",
    "        window = ' '.join(words[i:i + window_size])\n",
    "        found = sum(1 for k in keywords if re.search(r'\\b' + re.escape(k) + r'\\b', window))\n",
    "        if found >= 1:\n",
    "            return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "#Remove any potential duplication in tweets (because of multiple scraping sessions)\n",
    "def remove_duplicate_rows(df, columns_to_check):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows from a DataFrame, keeping only the latest instance.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    columns_to_check (list): A list of column names to check for duplicates.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with duplicate rows removed.\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by the columns to check, in descending order\n",
    "    df = df.sort_values(by=columns_to_check, ascending=False)\n",
    "    \n",
    "    # Drop duplicate rows, keeping the first occurrence\n",
    "    df = df.drop_duplicates(subset=columns_to_check, keep='first')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: CONCATENATE ALL FILES IN PARSED DATA FOLDER\n",
    "The output will be the Pre-processing.csv, which will be used to Step 2 below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Influencer: SabbySabs2\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: MsLaToshaBrown\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: RonFilipkowski\n",
      "Before corpus size: 3\n",
      "After corpus size: 20\n",
      "\n",
      "Influencer: KyleKulinski\n",
      "Before corpus size: 0\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: funder\n",
      "Before corpus size: 0\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: mmpadellan\n",
      "Before corpus size: 0\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: krystalball\n",
      "Before corpus size: 0\n",
      "After corpus size: 8\n",
      "\n",
      "Influencer: SteveSchmidtSES\n",
      "Before corpus size: 4\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: robreiner\n",
      "Before corpus size: 1\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: marceelias\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TheRickWilson\n",
      "Before corpus size: 5\n",
      "After corpus size: 8\n",
      "\n",
      "Influencer: davidsirota\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: TristanSnell\n",
      "Before corpus size: 0\n",
      "After corpus size: 16\n",
      "\n",
      "Influencer: KyleClark\n",
      "Before corpus size: 1\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: PatrickSvitek\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: evanasmith\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BarbMcQuade\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: JohnArchibald\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: natsechobbyist\n",
      "Before corpus size: 1\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: davidhogg111\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: anthonyzenkus\n",
      "Before corpus size: 2\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: briebriejoy\n",
      "Before corpus size: 5\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: fred_guttenberg\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: JordanChariton\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: kylegriffin1\n",
      "Before corpus size: 2\n",
      "After corpus size: 16\n",
      "\n",
      "Influencer: itsJeffTiedrich\n",
      "Before corpus size: 4\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: bluestein\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: Josh_Moon\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: WarOnDumb\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: ProudSocialist\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: maryltrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: JoJoFromJerz\n",
      "Before corpus size: 3\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: MollyJongFast\n",
      "Before corpus size: 4\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: aaronjmate\n",
      "Before corpus size: 10\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: checkmatestate\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: jimmy_dore\n",
      "Before corpus size: 2\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: bshelburne\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: LeeCamp\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: SocialistMMA\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: spiritofho\n",
      "Before corpus size: 3\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: FiorellaIsabelM\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: RealSpikeCohen\n",
      "Before corpus size: 2\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: ComicDaveSmith\n",
      "Before corpus size: 9\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: HannahDCox\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BillOReilly\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: ThomasEWoods\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: FreemansMind96\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: DavidAFrench\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: gtconway3d\n",
      "Before corpus size: 0\n",
      "After corpus size: 9\n",
      "\n",
      "Influencer: spann\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: Jaybefaunt\n",
      "Before corpus size: 0\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: BernardKerik\n",
      "Before corpus size: 3\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: jeff_poor\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TomFitton\n",
      "Before corpus size: 5\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: brad_polumbo\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: IngrahamAngle\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: seanhannity\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: charliekirk11\n",
      "Before corpus size: 0\n",
      "After corpus size: 13\n",
      "\n",
      "Influencer: TuckerCarlson\n",
      "Before corpus size: 0\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: AnnCoulter\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: EricTrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: LaraLeaTrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: PatTheSocialist\n",
      "Before corpus size: 0\n",
      "After corpus size: 9\n",
      "\n",
      "Influencer: NancyAFrench\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: donwinslow\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BobMurphyEcon\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: benshapiro\n",
      "Before corpus size: 12\n",
      "After corpus size: 33\n",
      "\n",
      "Influencer: elonmusk\n",
      "Before corpus size: 7\n",
      "After corpus size: 13\n",
      "\n",
      "Influencer: SarcasmStardust\n",
      "Before corpus size: 1\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: toddcstacy\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: DineshDSouza\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: dbongino\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TheLeoTerrell\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: donaldjtrumpjr\n",
      "Before corpus size: 3\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: diamondandsilk\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: michaelmalice\n",
      "Before corpus size: 1\n",
      "After corpus size: 7\n",
      "\n",
      "Influencer: tomilahren\n",
      "Before corpus size: 1\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: glennbeck\n",
      "Before corpus size: 1\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: coachbrucepearl\n",
      "Before corpus size: 2\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: bennyjohnson\n",
      "Before corpus size: 0\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: marklevinshow\n",
      "Before corpus size: 1\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: ksorbs\n",
      "Before corpus size: 1\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: atensnut\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: scottpresler\n",
      "Before corpus size: 0\n",
      "After corpus size: 7\n",
      "\n",
      "Influencer: pnjaban\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: hodgetwins\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Influencer:\n",
    "    name: str\n",
    "    affiliation: str\n",
    "    no_followers: int = 0\n",
    "    before_corpus: list = field(default_factory=list) \n",
    "    before_likes: list = field(default_factory=list)\n",
    "    before_retweets: list = field(default_factory=list)\n",
    "    after_corpus: list = field(default_factory=list)\n",
    "    after_likes: list = field(default_factory=list)\n",
    "    after_retweets: list = field(default_factory=list)\n",
    "\n",
    "data = []\n",
    "account_list = []\n",
    "\n",
    "#Loading File paths\n",
    "supplementary_folder = \"Supplementary Materials\"\n",
    "influencers_path = os.path.join(supplementary_folder, \"Followers List & Categories - Accounts Kept.csv\")\n",
    "\n",
    "#Population the data file with initial data of the available influencers\n",
    "with open(influencers_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader) #skip header\n",
    "    for line in reader:\n",
    "        name = line[0]\n",
    "        account_list.append(name[1:]) #Creating a list of influencers account names\n",
    "\n",
    "        affiliation = line[1]\n",
    "        # if affiliation == \" Libertarian Party\":\n",
    "        #     affiliation = affiliation[1:]\n",
    "\n",
    "        followers = line[2]\n",
    "        if affiliation or followers:\n",
    "            data.append(Influencer(name[1:], affiliation, followers))\n",
    "\n",
    "parsed_before_folder = os.path.join(\"Parsed Data\", \"Before\")\n",
    "parsed_after_folder = os.path.join(\"Parsed Data\", \"After\")\n",
    "\n",
    "before_files = [f for f in os.listdir(parsed_before_folder) if f.endswith('.csv')] #Getting all before files\n",
    "after_files = [f for f in os.listdir(parsed_after_folder) if f.endswith('.csv')] #Getting all after files\n",
    "\n",
    "def getting_values(files: list, path: str, after: bool):\n",
    "    for f in files:\n",
    "        with open(f\"{path}/{f}\", 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            next(reader) #skip header\n",
    "            \n",
    "            for line in reader:\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                if line[0] == \"|RUN STATISTICS|\": # End of file, move on to next file\n",
    "                    break\n",
    "            \n",
    "                name = line[0].strip() if line else \"\"\n",
    "                tweet = line[2].strip()\n",
    "                date = line[1]\n",
    "                like = int(line[3].strip())\n",
    "                retweet = int(line[4].strip())\n",
    "\n",
    "                for i in data:\n",
    "                    if name == i.name:\n",
    "                        if after and (tweet not in c for c in i.after_corpus) and like >1000 and not_palestine_OH(tweet):\n",
    "                                i.after_corpus.append(tweet)\n",
    "                                i.after_likes.append(like)\n",
    "                                i.after_retweets.append(retweet)\n",
    "                        else:\n",
    "                            if (tweet not in c for c in i.before_corpus) and like > 1000 and not_palestine_OH(tweet):\n",
    "                                i.before_corpus.append(tweet)\n",
    "                                i.before_likes.append(like)\n",
    "                                i.before_retweets.append(retweet)\n",
    "\n",
    "getting_values(before_files, parsed_before_folder, False)\n",
    "getting_values(after_files, parsed_after_folder, True)\n",
    "\n",
    "# Check results for each influencer\n",
    "for i in data:\n",
    "    print(f\"\\nInfluencer: {i.name}\")\n",
    "    print(f\"Before corpus size: {len(i.before_corpus)}\")\n",
    "    # print(f\"Before likes list: {(i.before_likes)}\")\n",
    "    # print(f\"Before retweets list: {(i.before_retweets)}\")\n",
    "    print(f\"After corpus size: {len(i.after_corpus)}\")\n",
    "    # print(f\"After likes list: {(i.after_likes)}\")\n",
    "    # print(f\"After retweets list: {(i.after_retweets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Supplementary Materials/Pre-processing.csv\", 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Name','Affiliation', 'Number of Followers', \"Before Corpus\", \"Before List of Likes\", \"Before List of Retweets\", \"After Corpus\", \"After List of Likes\", \"After List of Retweets\"])\n",
    "    \n",
    "        for i in data:\n",
    "            if i.before_corpus and i.after_corpus:\n",
    "                writer.writerow([i.name, i.affiliation, i.no_followers, i.before_corpus, i.before_likes, i.before_retweets, i.after_corpus, i.after_likes, i.after_retweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: SUBJECT ANONYMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Number of Followers</th>\n",
       "      <th>Before Corpus</th>\n",
       "      <th>Before List of Likes</th>\n",
       "      <th>Before List of Retweets</th>\n",
       "      <th>After Corpus</th>\n",
       "      <th>After List of Likes</th>\n",
       "      <th>After List of Retweets</th>\n",
       "      <th>Subject ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RonFilipkowski</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>['Dershowitz said Trump asked him at dinner wh...</td>\n",
       "      <td>[1337, 7377, 7417]</td>\n",
       "      <td>[303, 1882, 1888]</td>\n",
       "      <td>['How odd for Trump to Blame America First for...</td>\n",
       "      <td>[1520, 2370, 1244, 1440, 2369, 34866, 3056, 15...</td>\n",
       "      <td>[363, 703, 229, 476, 702, 18715, 597, 363, 477...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SteveSchmidtSES</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>['A direct threat against American Jews by a d...</td>\n",
       "      <td>[1223, 1420, 1420, 1238]</td>\n",
       "      <td>[251, 459, 459, 254]</td>\n",
       "      <td>['\"The corruption of one man in Israel has bro...</td>\n",
       "      <td>[4262, 4259, 13223, 4230]</td>\n",
       "      <td>[1588, 1586, 4037, 1580]</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheRickWilson</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>['The purpose of terrorism is to terrorize.', ...</td>\n",
       "      <td>[6283, 6283, 6242, 6289, 3502]</td>\n",
       "      <td>[732, 732, 730, 732, 460]</td>\n",
       "      <td>['If you think its bad thing that the leaders ...</td>\n",
       "      <td>[3334, 1634, 2311, 3333, 1633, 2308, 3309, 3046]</td>\n",
       "      <td>[315, 304, 218, 317, 304, 218, 316, 658]</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natsechobbyist</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>477600.0</td>\n",
       "      <td>['My daughter is at Hebrew school this morning...</td>\n",
       "      <td>[3510]</td>\n",
       "      <td>[83]</td>\n",
       "      <td>['I despise Bibi.  I don’t think it’s a genoci...</td>\n",
       "      <td>[1568, 2340, 4235]</td>\n",
       "      <td>[595, 540, 683]</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anthonyzenkus</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>88800.0</td>\n",
       "      <td>['You cannot say you care about women in Iran ...</td>\n",
       "      <td>[1471, 1464]</td>\n",
       "      <td>[642, 642]</td>\n",
       "      <td>['They release this the day we find out that I...</td>\n",
       "      <td>[1739, 1505, 1305, 5419, 1016, 1008]</td>\n",
       "      <td>[190, 619, 488, 2199, 741, 733]</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name       Affiliation  Number of Followers  \\\n",
       "0   RonFilipkowski  Democratic Party            1000000.0   \n",
       "1  SteveSchmidtSES  Democratic Party            1500000.0   \n",
       "2    TheRickWilson  Democratic Party            1600000.0   \n",
       "3   natsechobbyist  Democratic Party             477600.0   \n",
       "4    anthonyzenkus  Democratic Party              88800.0   \n",
       "\n",
       "                                       Before Corpus  \\\n",
       "0  ['Dershowitz said Trump asked him at dinner wh...   \n",
       "1  ['A direct threat against American Jews by a d...   \n",
       "2  ['The purpose of terrorism is to terrorize.', ...   \n",
       "3  ['My daughter is at Hebrew school this morning...   \n",
       "4  ['You cannot say you care about women in Iran ...   \n",
       "\n",
       "             Before List of Likes    Before List of Retweets  \\\n",
       "0              [1337, 7377, 7417]          [303, 1882, 1888]   \n",
       "1        [1223, 1420, 1420, 1238]       [251, 459, 459, 254]   \n",
       "2  [6283, 6283, 6242, 6289, 3502]  [732, 732, 730, 732, 460]   \n",
       "3                          [3510]                       [83]   \n",
       "4                    [1471, 1464]                 [642, 642]   \n",
       "\n",
       "                                        After Corpus  \\\n",
       "0  ['How odd for Trump to Blame America First for...   \n",
       "1  ['\"The corruption of one man in Israel has bro...   \n",
       "2  ['If you think its bad thing that the leaders ...   \n",
       "3  ['I despise Bibi.  I don’t think it’s a genoci...   \n",
       "4  ['They release this the day we find out that I...   \n",
       "\n",
       "                                 After List of Likes  \\\n",
       "0  [1520, 2370, 1244, 1440, 2369, 34866, 3056, 15...   \n",
       "1                          [4262, 4259, 13223, 4230]   \n",
       "2   [3334, 1634, 2311, 3333, 1633, 2308, 3309, 3046]   \n",
       "3                                 [1568, 2340, 4235]   \n",
       "4               [1739, 1505, 1305, 5419, 1016, 1008]   \n",
       "\n",
       "                              After List of Retweets  Subject ID  \n",
       "0  [363, 703, 229, 476, 702, 18715, 597, 363, 477...          39  \n",
       "1                           [1588, 1586, 4037, 1580]          92  \n",
       "2           [315, 304, 218, 317, 304, 218, 316, 658]          60  \n",
       "3                                    [595, 540, 683]          77  \n",
       "4                    [190, 619, 488, 2199, 741, 733]          63  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Supplementary Materials/Pre-processing.csv\")\n",
    "\n",
    "# Generate random IDs for all subjects - uncomment to generate initial Ledger file\n",
    "# random_ids = random.sample(range(10, 99), len(df))  # Modified to match DataFrame length\n",
    "\n",
    "# # Assign random IDs directly to the Subject ID column\n",
    "# df[\"Subject ID\"] = random_ids\n",
    "\n",
    "# #Use to create new ledger file\n",
    "# df_nametoID = df[[\"Name\", \"Subject ID\"]]\n",
    "# df_nametoID.head()\n",
    "# df_nametoID.to_csv('Supplementary Materials/Subject Ledger.csv', index=False) \n",
    "\n",
    "\n",
    "# Load in existing Ledger file\n",
    "ledger = pd.read_csv(\"Supplementary Materials/Subject Ledger.csv\") \n",
    "ledger_records = ledger.to_dict(orient='records')\n",
    "\n",
    "ledger_dict = {}\n",
    "\n",
    "for l in ledger_records:\n",
    "    ledger_dict[l['Name']] = l['Subject ID']\n",
    "\n",
    "df[\"Subject ID\"] = df[\"Name\"].map(ledger_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noName = df[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Before Corpus\", \"Before List of Likes\", \"Before List of Retweets\", \"After Corpus\", \"After List of Likes\", \"After List of Retweets\"]]\n",
    "\n",
    "df_noName.to_csv(\"Cleaned Data/All_NN_Cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTRAST CODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noName[\"Contrast\"] = 0.0\n",
    "\n",
    "affiliation_dict = {\n",
    "    \"Republican Party\": -0.5,\n",
    "    \"Democratic Party\": 0.5\n",
    "    # \"Other\": 0.0\n",
    "}\n",
    "\n",
    "df_noName[\"Contrast\"] = df_noName[\"Affiliation\"].map(affiliation_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before\n",
    "df_noName_B = df_noName[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Before Corpus\", \"Before List of Likes\", \"Before List of Retweets\", \"Contrast\"]]\n",
    "#After\n",
    "df_noName_A = df_noName[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"After Corpus\", \"After List of Likes\", \"After List of Retweets\", \"Contrast\"]]\n",
    "\n",
    "#Convert strings representation of list into list\n",
    "df_noName_A.loc[:, \"After Corpus\"] = df_noName_A['After Corpus'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After List of Likes\"] = df_noName_A['After List of Likes'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After List of Retweets\"] = df_noName_A['After List of Retweets'].apply(ast.literal_eval)\n",
    "\n",
    "df_noName_B.loc[:, \"Before Corpus\"] = df_noName_B['Before Corpus'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before List of Likes\"] = df_noName_B['Before List of Likes'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before List of Retweets\"] = df_noName_B['Before List of Retweets'].apply(ast.literal_eval)\n",
    "\n",
    "#Explode all three columns\n",
    "df_noName_A = df_noName_A.explode(['After Corpus', 'After List of Likes', 'After List of Retweets']).reset_index(drop=True)\n",
    "df_noName_B = df_noName_B.explode(['Before Corpus', 'Before List of Likes', 'Before List of Retweets']).reset_index(drop=True)\n",
    "\n",
    "df_noName_A = remove_duplicate_rows(df_noName_A, \"After Corpus\")\n",
    "df_noName_B = remove_duplicate_rows(df_noName_B, \"Before Corpus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate random IDs for all tweets - uncomment to generate initial Ledger file\n",
    "# tweets_random_ids = random.sample(range(100, 999), len(df_noName_A) + len(df_noName_B))  # Modified to match DataFrame length\n",
    "\n",
    "# # Assign random IDs directly to the Subject ID column\n",
    "# df_noName_A[\"Tweet ID\"] = tweets_random_ids[:len(df_noName_A)]\n",
    "# df_noName_B[\"Tweet ID\"] = tweets_random_ids[len(df_noName_A):]\n",
    "\n",
    "# # Select and rename columns to have a common column name \"Corpus\" \n",
    "# df_tweet_before = df_noName_B[[\"Tweet ID\", \"Before Corpus\"]].rename(columns={\"Before Corpus\": \"Corpus\"}) \n",
    "# df_tweet_after = df_noName_A[[\"Tweet ID\", \"After Corpus\"]].rename(columns={\"After Corpus\": \"Corpus\"}) \n",
    "\n",
    "# # Add a new column to indicate the source of the corpus \n",
    "# df_tweet_before[\"Source\"] = \"Before\" \n",
    "# df_tweet_after[\"Source\"] = \"After\" \n",
    "\n",
    "# # Concatenate the DataFrames \n",
    "# df_tweet_ledger = pd.concat([df_tweet_before, df_tweet_after], ignore_index=True)\n",
    "# df_tweet_ledger.head()\n",
    "# df_tweet_ledger.to_csv('Supplementary Materials/Tweets Ledger.csv', index=False) #Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in existing Ledger file\n",
    "tweet_ledger = pd.read_csv(\"Supplementary Materials/Tweets Ledger.csv\") \n",
    "tweet_ledger_records = tweet_ledger.to_dict(orient='records')\n",
    "tweet_ledger_dict = {}\n",
    "\n",
    "for l in tweet_ledger_records:\n",
    "    tweet_ledger_dict[l['Corpus']] = l['Tweet ID']\n",
    "\n",
    "df_noName_A[\"Tweet ID\"] = df_noName_A[\"After Corpus\"].map(tweet_ledger_dict)\n",
    "df_noName_B[\"Tweet ID\"] = df_noName_B[\"Before Corpus\"].map(tweet_ledger_dict)\n",
    "\n",
    "# df_noName_B.head()\n",
    "\n",
    "#Reordering the columns\n",
    "df_noName_B = df_noName_B[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Tweet ID\", \"Contrast\", \"Before Corpus\", \"Before List of Likes\", \"Before List of Retweets\"]]\n",
    "df_noName_A = df_noName_A[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Tweet ID\", \"Contrast\", \"After Corpus\", \"After List of Likes\", \"After List of Retweets\"]]\n",
    "\n",
    "#Exporting the DF to csv\n",
    "df_noName_A.to_csv('Cleaned Data/After_NN_Cleaned.csv', index=False) \n",
    "df_noName_B.to_csv('Cleaned Data/Before_NN_Cleaned.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|STATISTICS|\n",
      "Before Tweets: 64\n",
      "After Tweets: 154\n",
      "Number of Democratic Influencer: 13\n",
      "Number of Republican Influencer: 14\n",
      "Number of Democrats Tweets After: 67\n",
      "Number of Republican Tweets After: 87\n",
      "Number of Democrats Tweets Before: 30\n",
      "Number of Republican Tweets Before: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"|STATISTICS|\")\n",
    "print(f\"Before Tweets: {len(df_noName_B)}\")\n",
    "print(f\"After Tweets: {len(df_noName_A)}\")\n",
    "print(f\"Number of Democratic Influencer: {sum(df_noName['Affiliation'] == 'Democratic Party')}\")\n",
    "print(f\"Number of Republican Influencer: {sum(df_noName['Affiliation'] == 'Republican Party')}\")\n",
    "print(f\"Number of Democrats Tweets After: {sum(df_noName_A['Affiliation'] == 'Democratic Party')}\")\n",
    "print(f\"Number of Republican Tweets After: {sum(df_noName_A['Affiliation'] == 'Republican Party')}\")\n",
    "print(f\"Number of Democrats Tweets Before: {sum(df_noName_B['Affiliation'] == 'Democratic Party')}\")\n",
    "print(f\"Number of Republican Tweets Before: {sum(df_noName_B['Affiliation'] == 'Republican Party')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
