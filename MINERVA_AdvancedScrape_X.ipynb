{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff4fd40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen  \n",
    "from tqdm import tqdm\n",
    "from lxml import html\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "# from screeninfo import get_monitors\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe0483",
   "metadata": {},
   "source": [
    "# US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1150ec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevBlackNetwork\n",
      "TheDemocrats\n",
      "msnbc\n",
      "FoxNews\n",
      "TheAtlantic\n",
      "aldotcom\n",
      "JudiciaryGOP\n",
      "MSNBC\n",
      "NBCNews\n",
      "RandPaul\n",
      "politico\n",
      "joncoopertweets\n",
      "HomelandDems\n",
      "HouseJudiciary\n",
      "RepSwalwell\n",
      "NPR\n",
      "CNN\n",
      "LPMisesCaucus\n",
      "RealSpikeCohen\n",
      "YATPOfficial\n",
      "justinamash\n",
      "tedlieu\n",
      "LPNational\n",
      "ToddHagopian\n",
      "theintercept\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RevBlackNetwork',\n",
       " 'TheDemocrats',\n",
       " 'msnbc',\n",
       " 'FoxNews',\n",
       " 'TheAtlantic',\n",
       " 'aldotcom',\n",
       " 'JudiciaryGOP',\n",
       " 'MSNBC',\n",
       " 'NBCNews',\n",
       " 'RandPaul',\n",
       " 'politico',\n",
       " 'joncoopertweets',\n",
       " 'HomelandDems',\n",
       " 'HouseJudiciary',\n",
       " 'RepSwalwell',\n",
       " 'NPR',\n",
       " 'CNN',\n",
       " 'LPMisesCaucus',\n",
       " 'RealSpikeCohen',\n",
       " 'YATPOfficial',\n",
       " 'justinamash',\n",
       " 'tedlieu',\n",
       " 'LPNational',\n",
       " 'ToddHagopian',\n",
       " 'theintercept']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# followers_US = pd.read_csv('Influencers_US_final.csv')\n",
    "# followers_US.head()\n",
    "\n",
    "followers_US = []\n",
    "with open('followers_US.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if \"@\" in line:\n",
    "            follower = line.strip()[1:]\n",
    "            print(follower)\n",
    "            followers_US.append(follower)\n",
    "f.close()\n",
    "\n",
    "followers_US\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f51ae072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# followers_US_list = followers_US.Influencer_Xhandle.tolist()\n",
    "\n",
    "# count = Counter(followers_US)\n",
    "\n",
    "# followers_US = []\n",
    "\n",
    "# for key, value in count.items():\n",
    "#     if value > 2:\n",
    "#         followers_US.append(key)\n",
    "        \n",
    "# followers_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3565ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dict_US = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c11ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://twitter.com/i/flow/login')\n",
    "wait = WebDriverWait(driver, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f177a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log in\n",
    "\n",
    "# Username\n",
    "username = wait.until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'input[autocomplete=username]'))\n",
    ")\n",
    "username.send_keys(\"rigautam@udel.edu\")\n",
    "time.sleep(3)\n",
    "login_button = wait.until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, '[role=button].r-13qz1uu'))\n",
    ")\n",
    "login_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "try: \n",
    "    # Password\n",
    "    password = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, '[type=password]'))\n",
    "    )\n",
    "    password.send_keys(\"Sus1234!\")\n",
    "    time.sleep(3)\n",
    "    login_button = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, '[data-testid*=Login_Button]'))\n",
    "    )\n",
    "    login_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "except: # if we get an error\n",
    "    username = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-testid*=ocfEnterTextTextInput]\"))\n",
    "    )\n",
    "    username.send_keys(\"RichaGotem\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    next_button = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-testid*=ocfEnterTextNextButton]\"))\n",
    "    )\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    password = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"[name*=password]\"))\n",
    "    )\n",
    "    password.send_keys(\"Sus1234!\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    login_button = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-testid*=LoginForm_Login_Button]\"))\n",
    "    )\n",
    "    login_button.click()\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70948d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealSpikeCohen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [01:13<00:23,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YATPOfficial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [02:15<00:39,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "justinamash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [03:35<00:57, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tedlieu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [04:47<01:03, 21.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LPNational\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [05:57<00:55, 27.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToddHagopian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [07:05<00:34, 34.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theintercept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [08:30<00:00, 20.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Function to check if the Fetch More button is present\n",
    "def is_element_present(driver, xpath):\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, xpath)\n",
    "        return element.is_displayed()\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "\n",
    "count = 0\n",
    "\n",
    "keyword1 = \"(Gaza* OR Israel* OR (West OR AND OR Bank) OR (Tel OR AND OR Aviv) OR (Tel OR AND OR Aviv-Yafo) OR Bedouin* OR Palestin* OR Middle OR East* OR Middle OR Eastern OR Jew* OR rabbi OR Muslim* OR Islam* OR Jihad OR Antisemiti* OR Zionis* OR IDF)\"\n",
    "keyword2 = \"(IOF OR Hamas OR Massacre OR Genocide OR Ceasefire OR Terroris* OR Netanyahu OR Histadrut OR Haniyeh OR Yahya OR Sinwar OR Fatah OR Mohammed OR Deif)\"\n",
    "hashtags = \"(# OR #IsraelPalestineWar OR #IsraelGazaWar OR #Gazabombing OR #CeasefireNOW OR #FreePalestine OR #StrikeForGaza OR #Gazagenocide)\"\n",
    "\n",
    "for profile in tqdm(followers_US):\n",
    "    \n",
    "    if profile not in tweets_dict_US.keys():\n",
    "        print(profile)\n",
    "\n",
    "        tweets_dict_US[profile] = []\n",
    "\n",
    "        ### Begin scrape\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Search\n",
    "        search_button = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '[aria-label=\"Search and explore\"]'))\n",
    "        )\n",
    "        search_button.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        search_bar = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '[aria-label=\"Search\"]'))\n",
    "        )\n",
    "        search_bar.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        for i in range(2): \n",
    "            search_query = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '[aria-label=\"Search query\"]')))\n",
    "\n",
    "            # Advanced search query\n",
    "            if i == 0:\n",
    "                search_query.send_keys(f'{keyword1} {hashtags} (from:{profile}) min_faves:1000 until:2024-09-14 since:2023-10-07 -filter:links -filter:replies')\n",
    "            if i == 1:\n",
    "                search_query.send_keys([Keys.BACKSPACE]*1000)\n",
    "                search_query.send_keys(f'{keyword2} {hashtags} (from:{profile}) min_faves:1000 until:2024-09-14 since:2023-10-07 -filter:links -filter:replies')\n",
    "\n",
    "            search_query.send_keys(Keys.RETURN)\n",
    "            time.sleep(6)\n",
    "            \n",
    "            # Scroll until you cannot scroll anymore\n",
    "            reached_page_end = False\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            retry_xpath = \"//button[@role='button' and @type='button']//span[text()='Retry']\"\n",
    "            # random.randrange(10, 15)\n",
    "            if (is_element_present(driver, retry_xpath)):\n",
    "                for i in range(5):\n",
    "                    search_button = wait.until(EC.element_to_be_clickable((By.XPATH, retry_xpath)))\n",
    "                    search_button.click()\n",
    "                    print(f'{profile} - {count} - Retry button appeared.')\n",
    "                time.sleep(10) \n",
    "\n",
    "            while not reached_page_end:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")   \n",
    "                time.sleep(3)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if last_height == new_height:\n",
    "                    reached_page_end = True\n",
    "                else:\n",
    "                    last_height = new_height\n",
    "            try:\n",
    "                # Select the home timeline div\n",
    "                search_results = driver.find_element(By.CSS_SELECTOR, '[aria-label=\"Timeline: Search timeline\"]')\n",
    "                # Just get all the HTML, will parse later\n",
    "                tweets_listed = search_results.get_attribute('innerHTML')\n",
    "                time.sleep(3)\n",
    "\n",
    "                # Append to dict\n",
    "                tweets_dict_US[profile].append(tweets_listed)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    count+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97adfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7de5e024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['RevBlackNetwork', 'TheDemocrats', 'msnbc', 'FoxNews', 'TheAtlantic', 'aldotcom', 'JudiciaryGOP', 'MSNBC', 'NBCNews', 'RandPaul', 'politico', 'joncoopertweets', 'HomelandDems', 'HouseJudiciary', 'RepSwalwell', 'NPR', 'CNN', 'LPMisesCaucus', 'RealSpikeCohen', 'YATPOfficial', 'justinamash', 'tedlieu', 'LPNational', 'ToddHagopian', 'theintercept'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dict_US.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3d896ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['RevBlackNetwork', 'TheDemocrats', 'msnbc', 'FoxNews', 'TheAtlantic', 'aldotcom', 'JudiciaryGOP', 'MSNBC', 'NBCNews', 'RandPaul', 'politico', 'joncoopertweets', 'HomelandDems', 'HouseJudiciary', 'RepSwalwell', 'NPR', 'CNN', 'LPMisesCaucus', 'RealSpikeCohen', 'YATPOfficial', 'justinamash', 'tedlieu', 'LPNational', 'ToddHagopian', 'theintercept'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dict_US_cleaned = {}\n",
    "    \n",
    "for key, value in tweets_dict_US.items():\n",
    "    if key not in tweets_dict_US_cleaned.keys():\n",
    "        tweets_dict_US_cleaned[key] = []\n",
    "        for v in value:\n",
    "            soup = BeautifulSoup(v, 'html.parser')\n",
    "            tweets = soup.find_all(attrs={\"data-testid\": \"tweetText\"})\n",
    "            for tweet in tweets:\n",
    "                tweet_text = tweet.get_text(strip=True)\n",
    "                tweets_dict_US_cleaned[key].append(tweet_text)\n",
    "\n",
    "tweets_dict_US_cleaned.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "862b1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"US_tweets.json\", 'w') as file:\n",
    "    json.dump(tweets_dict_US, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c5ac73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"US_tweets_cleaned.json\", 'w') as file:\n",
    "    json.dump(tweets_dict_US_cleaned, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
