{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/yn_f16552qvcz999s7pwv5sm0000gn/T/ipykernel_87146/1597882086.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field  # Import field\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: CONCATENATE ALL FILES IN PARSED DATA FOLDER\n",
    "The output will be the Pre-processing.csv, which will be used to Step 2 below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Influencer: SabbySabs2\n",
      "Before corpus size: 1\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: MsLaToshaBrown\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: RonFilipkowski\n",
      "Before corpus size: 12\n",
      "After corpus size: 20\n",
      "\n",
      "Influencer: KyleKulinski\n",
      "Before corpus size: 0\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: funder\n",
      "Before corpus size: 0\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: mmpadellan\n",
      "Before corpus size: 4\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: krystalball\n",
      "Before corpus size: 5\n",
      "After corpus size: 8\n",
      "\n",
      "Influencer: SteveSchmidtSES\n",
      "Before corpus size: 4\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: robreiner\n",
      "Before corpus size: 1\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: marceelias\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TheRickWilson\n",
      "Before corpus size: 5\n",
      "After corpus size: 8\n",
      "\n",
      "Influencer: davidsirota\n",
      "Before corpus size: 2\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: TristanSnell\n",
      "Before corpus size: 6\n",
      "After corpus size: 16\n",
      "\n",
      "Influencer: KyleClark\n",
      "Before corpus size: 1\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: PatrickSvitek\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: evanasmith\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BarbMcQuade\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: JohnArchibald\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: natsechobbyist\n",
      "Before corpus size: 1\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: davidhogg111\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: anthonyzenkus\n",
      "Before corpus size: 5\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: briebriejoy\n",
      "Before corpus size: 5\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: fred_guttenberg\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: JordanChariton\n",
      "Before corpus size: 0\n",
      "After corpus size: 7\n",
      "\n",
      "Influencer: kylegriffin1\n",
      "Before corpus size: 3\n",
      "After corpus size: 16\n",
      "\n",
      "Influencer: itsJeffTiedrich\n",
      "Before corpus size: 4\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: bluestein\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: Josh_Moon\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: WarOnDumb\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: ProudSocialist\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: maryltrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: JoJoFromJerz\n",
      "Before corpus size: 3\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: MollyJongFast\n",
      "Before corpus size: 4\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: aaronjmate\n",
      "Before corpus size: 10\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: checkmatestate\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: jimmy_dore\n",
      "Before corpus size: 3\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: bshelburne\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: LeeCamp\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: SocialistMMA\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: spiritofho\n",
      "Before corpus size: 3\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: FiorellaIsabelM\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: RealSpikeCohen\n",
      "Before corpus size: 4\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: ComicDaveSmith\n",
      "Before corpus size: 9\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: HannahDCox\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BillOReilly\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: ThomasEWoods\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: FreemansMind96\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: DavidAFrench\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: gtconway3d\n",
      "Before corpus size: 0\n",
      "After corpus size: 9\n",
      "\n",
      "Influencer: spann\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: Jaybefaunt\n",
      "Before corpus size: 0\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: BernardKerik\n",
      "Before corpus size: 3\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: jeff_poor\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TomFitton\n",
      "Before corpus size: 5\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: brad_polumbo\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: IngrahamAngle\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: seanhannity\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: charliekirk11\n",
      "Before corpus size: 8\n",
      "After corpus size: 13\n",
      "\n",
      "Influencer: TuckerCarlson\n",
      "Before corpus size: 1\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: AnnCoulter\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: EricTrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: LaraLeaTrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: PatTheSocialist\n",
      "Before corpus size: 0\n",
      "After corpus size: 9\n",
      "\n",
      "Influencer: NancyAFrench\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: donwinslow\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BobMurphyEcon\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: benshapiro\n",
      "Before corpus size: 12\n",
      "After corpus size: 34\n",
      "\n",
      "Influencer: elonmusk\n",
      "Before corpus size: 7\n",
      "After corpus size: 13\n",
      "\n",
      "Influencer: SarcasmStardust\n",
      "Before corpus size: 1\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: toddcstacy\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: DineshDSouza\n",
      "Before corpus size: 4\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: dbongino\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TheLeoTerrell\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: donaldjtrumpjr\n",
      "Before corpus size: 3\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: diamondandsilk\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: michaelmalice\n",
      "Before corpus size: 1\n",
      "After corpus size: 7\n",
      "\n",
      "Influencer: tomilahren\n",
      "Before corpus size: 2\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: glennbeck\n",
      "Before corpus size: 2\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: coachbrucepearl\n",
      "Before corpus size: 2\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: bennyjohnson\n",
      "Before corpus size: 6\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: marklevinshow\n",
      "Before corpus size: 1\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: ksorbs\n",
      "Before corpus size: 1\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: atensnut\n",
      "Before corpus size: 2\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: scottpresler\n",
      "Before corpus size: 4\n",
      "After corpus size: 7\n",
      "\n",
      "Influencer: pnjaban\n",
      "Before corpus size: 1\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: hodgetwins\n",
      "Before corpus size: 1\n",
      "After corpus size: 3\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Influencer:\n",
    "    name: str\n",
    "    affiliation: str\n",
    "    no_followers: int = 0\n",
    "    before_corpus: list = field(default_factory=list) \n",
    "    before_likes: list = field(default_factory=list)\n",
    "    before_retweets: list = field(default_factory=list)\n",
    "    after_corpus: list = field(default_factory=list)\n",
    "    after_likes: list = field(default_factory=list)\n",
    "    after_retweets: list = field(default_factory=list)\n",
    "\n",
    "data = []\n",
    "account_list = []\n",
    "\n",
    "#Loading File paths\n",
    "supplementary_folder = \"Supplementary Materials\"\n",
    "influencers_path = os.path.join(supplementary_folder, \"Followers List & Categories - Accounts Kept.csv\")\n",
    "\n",
    "#Population the data file with initial data of the available influencers\n",
    "with open(influencers_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader) #skip header\n",
    "    for line in reader:\n",
    "        name = line[0]\n",
    "        account_list.append(name[1:]) #Creating a list of influencers account names\n",
    "\n",
    "        affiliation = line[1]\n",
    "        # if affiliation == \" Libertarian Party\":\n",
    "        #     affiliation = affiliation[1:]\n",
    "\n",
    "        followers = line[2]\n",
    "        if affiliation or followers:\n",
    "            data.append(Influencer(name[1:], affiliation, followers))\n",
    "\n",
    "parsed_before_folder = os.path.join(\"Parsed Data\", \"Before\")\n",
    "parsed_after_folder = os.path.join(\"Parsed Data\", \"After\")\n",
    "\n",
    "before_files = [f for f in os.listdir(parsed_before_folder) if f.endswith('.csv')] #Getting all before files\n",
    "after_files = [f for f in os.listdir(parsed_after_folder) if f.endswith('.csv')] #Getting all after files\n",
    "\n",
    "def getting_values(files: list, path: str, after: bool):\n",
    "    for f in files:\n",
    "        with open(f\"{path}/{f}\", 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            next(reader) #skip header\n",
    "            \n",
    "            for line in reader:\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                if line[0] == \"|RUN STATISTICS|\": # End of file, move on to next file\n",
    "                    break\n",
    "            \n",
    "                name = line[0].strip() if line else \"\"\n",
    "                tweet = line[2].strip()\n",
    "                date = line[1]\n",
    "                like = int(line[3].strip())\n",
    "                retweet = int(line[4].strip())\n",
    "\n",
    "                for i in data:\n",
    "                    if name == i.name:\n",
    "                        if after and (tweet not in c for c in i.after_corpus):\n",
    "                                i.after_corpus.append(tweet)\n",
    "                                i.after_likes.append(like)\n",
    "                                i.after_retweets.append(retweet)\n",
    "                        else:\n",
    "                            if (tweet not in c for c in i.before_corpus):\n",
    "                                i.before_corpus.append(tweet)\n",
    "                                i.before_likes.append(like)\n",
    "                                i.before_retweets.append(retweet)\n",
    "\n",
    "getting_values(before_files, parsed_before_folder, False)\n",
    "getting_values(after_files, parsed_after_folder, True)\n",
    "\n",
    "\n",
    "# Check results for each influencer\n",
    "for i in data:\n",
    "    print(f\"\\nInfluencer: {i.name}\")\n",
    "    print(f\"Before corpus size: {len(i.before_corpus)}\")\n",
    "    # print(f\"Before likes list: {(i.before_likes)}\")\n",
    "    # print(f\"Before retweets list: {(i.before_retweets)}\")\n",
    "    print(f\"After corpus size: {len(i.after_corpus)}\")\n",
    "    # print(f\"After likes list: {(i.after_likes)}\")\n",
    "    # print(f\"After retweets list: {(i.after_retweets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Supplementary Materials/Pre-processing.csv\", 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Name','Affiliation', 'Number of Followers', \"Before Corpus\", \"Before List of Likes\", \"Before List of Retweets\", \"After Corpus\", \"After List of Likes\", \"After List of Retweets\"])\n",
    "    \n",
    "        for i in data:\n",
    "            if i.before_corpus and i.after_corpus:\n",
    "                writer.writerow([i.name, i.affiliation, i.no_followers, i.before_corpus, i.before_likes, i.before_retweets, i.after_corpus, i.after_likes, i.after_retweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: SUBJECT ANONYMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Number of Followers</th>\n",
       "      <th>Before Corpus</th>\n",
       "      <th>Before List of Likes</th>\n",
       "      <th>Before List of Retweets</th>\n",
       "      <th>After Corpus</th>\n",
       "      <th>After List of Likes</th>\n",
       "      <th>After List of Retweets</th>\n",
       "      <th>Subject ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SabbySabs2</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>75700</td>\n",
       "      <td>['Every resident in East Palestine, OH should ...</td>\n",
       "      <td>[1322]</td>\n",
       "      <td>[488]</td>\n",
       "      <td>['Ilhan Omar: \"If you really wanted a ceasefir...</td>\n",
       "      <td>[1275, 2264]</td>\n",
       "      <td>[429, 681]</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RonFilipkowski</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1000000</td>\n",
       "      <td>['Dershowitz said Trump asked him at dinner wh...</td>\n",
       "      <td>[1337, 7409, 1012, 25397, 7377, 1331, 1578, 25...</td>\n",
       "      <td>[303, 1887, 208, 6635, 1882, 305, 420, 6617, 1...</td>\n",
       "      <td>['How odd for Trump to Blame America First for...</td>\n",
       "      <td>[1520, 2370, 1244, 1440, 2369, 34866, 3056, 15...</td>\n",
       "      <td>[363, 703, 229, 476, 702, 18715, 597, 363, 477...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mmpadellan</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1300000</td>\n",
       "      <td>['Even Fox News knows that the deregulation by...</td>\n",
       "      <td>[1069, 24343, 1078, 24557]</td>\n",
       "      <td>[314, 16978, 315, 17047]</td>\n",
       "      <td>['While Democrats push for ceasefire and human...</td>\n",
       "      <td>[3900, 5003, 29181, 3901, 5852, 15884, 5008, 2...</td>\n",
       "      <td>[2146, 1190, 7332, 2149, 612, 2544, 1192, 7337...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>krystalball</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>587700</td>\n",
       "      <td>['CNN had a literal lobbyist for Norfolk South...</td>\n",
       "      <td>[4215, 1991, 14437, 4236, 2000]</td>\n",
       "      <td>[1211, 457, 3108, 1220, 459]</td>\n",
       "      <td>['The targeting of Al Shifa hospital, is also ...</td>\n",
       "      <td>[1753, 10846, 3408, 1704, 8826, 1747, 1266, 2145]</td>\n",
       "      <td>[670, 3168, 591, 520, 2242, 666, 480, 717]</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SteveSchmidtSES</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1500000</td>\n",
       "      <td>['A direct threat against American Jews by a d...</td>\n",
       "      <td>[1223, 1420, 1420, 1238]</td>\n",
       "      <td>[251, 459, 459, 254]</td>\n",
       "      <td>['\"The corruption of one man in Israel has bro...</td>\n",
       "      <td>[4262, 4259, 13223, 4230]</td>\n",
       "      <td>[1588, 1586, 4037, 1580]</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name       Affiliation  Number of Followers  \\\n",
       "0       SabbySabs2  Democratic Party                75700   \n",
       "1   RonFilipkowski  Democratic Party              1000000   \n",
       "2       mmpadellan  Democratic Party              1300000   \n",
       "3      krystalball  Democratic Party               587700   \n",
       "4  SteveSchmidtSES  Democratic Party              1500000   \n",
       "\n",
       "                                       Before Corpus  \\\n",
       "0  ['Every resident in East Palestine, OH should ...   \n",
       "1  ['Dershowitz said Trump asked him at dinner wh...   \n",
       "2  ['Even Fox News knows that the deregulation by...   \n",
       "3  ['CNN had a literal lobbyist for Norfolk South...   \n",
       "4  ['A direct threat against American Jews by a d...   \n",
       "\n",
       "                                Before List of Likes  \\\n",
       "0                                             [1322]   \n",
       "1  [1337, 7409, 1012, 25397, 7377, 1331, 1578, 25...   \n",
       "2                         [1069, 24343, 1078, 24557]   \n",
       "3                    [4215, 1991, 14437, 4236, 2000]   \n",
       "4                           [1223, 1420, 1420, 1238]   \n",
       "\n",
       "                             Before List of Retweets  \\\n",
       "0                                              [488]   \n",
       "1  [303, 1887, 208, 6635, 1882, 305, 420, 6617, 1...   \n",
       "2                           [314, 16978, 315, 17047]   \n",
       "3                       [1211, 457, 3108, 1220, 459]   \n",
       "4                               [251, 459, 459, 254]   \n",
       "\n",
       "                                        After Corpus  \\\n",
       "0  ['Ilhan Omar: \"If you really wanted a ceasefir...   \n",
       "1  ['How odd for Trump to Blame America First for...   \n",
       "2  ['While Democrats push for ceasefire and human...   \n",
       "3  ['The targeting of Al Shifa hospital, is also ...   \n",
       "4  ['\"The corruption of one man in Israel has bro...   \n",
       "\n",
       "                                 After List of Likes  \\\n",
       "0                                       [1275, 2264]   \n",
       "1  [1520, 2370, 1244, 1440, 2369, 34866, 3056, 15...   \n",
       "2  [3900, 5003, 29181, 3901, 5852, 15884, 5008, 2...   \n",
       "3  [1753, 10846, 3408, 1704, 8826, 1747, 1266, 2145]   \n",
       "4                          [4262, 4259, 13223, 4230]   \n",
       "\n",
       "                              After List of Retweets  Subject ID  \n",
       "0                                         [429, 681]          97  \n",
       "1  [363, 703, 229, 476, 702, 18715, 597, 363, 477...          92  \n",
       "2  [2146, 1190, 7332, 2149, 612, 2544, 1192, 7337...          52  \n",
       "3         [670, 3168, 591, 520, 2242, 666, 480, 717]          87  \n",
       "4                           [1588, 1586, 4037, 1580]          62  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Supplementary Materials/Pre-processing.csv\")\n",
    "\n",
    "# random_ids = random.sample(range(10, 99), 41) Can be used to create Random IDs\n",
    "\n",
    "ledger = pd.read_csv(\"Supplementary Materials/Ledger.csv\") # Load in existing Ledger file\n",
    "ledger_records = ledger.to_dict(orient='records')\n",
    "\n",
    "ledger_dict = {}\n",
    "\n",
    "for l in ledger_records:\n",
    "    ledger_dict[l['Name']] = l['Subject ID']\n",
    "\n",
    "df[\"Subject ID\"] = df[\"Name\"].map(ledger_dict)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to create new ledger file\n",
    "# df_nametoID = df[[\"Name\", \"Subject ID\"]]\n",
    "# df_nametoID.to_csv('Supplementary Materials/Ledger.csv', index=False) \n",
    "\n",
    "df_noName = df[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Before Corpus\", \"Before List of Likes\", \"Before List of Retweets\", \"After Corpus\", \"After List of Likes\", \"After List of Retweets\"]]\n",
    "\n",
    "df_noName.to_csv(\"Cleaned Data/All_NN_Cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTRAST CODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noName[\"Contrast\"] = 0.0\n",
    "\n",
    "affiliation_dict = {\n",
    "    \"Republican Party\": -0.5,\n",
    "    \"Democratic Party\": 0.5,\n",
    "    \"Other\": 0.0\n",
    "}\n",
    "\n",
    "df_noName[\"Contrast\"] = df_noName[\"Affiliation\"].map(affiliation_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noName_B = df_noName[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Before Corpus\", \"Before List of Likes\", \"Before List of Retweets\"]]\n",
    "\n",
    "df_noName_A = df_noName[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"After Corpus\", \"After List of Likes\", \"After List of Retweets\"]]\n",
    "\n",
    "\n",
    "#Convert strings representation of list into list\n",
    "df_noName_A.loc[:, \"After Corpus\"] = df_noName_A['After Corpus'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After List of Likes\"] = df_noName_A['After List of Likes'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After List of Retweets\"] = df_noName_A['After List of Retweets'].apply(ast.literal_eval)\n",
    "\n",
    "df_noName_B.loc[:, \"Before Corpus\"] = df_noName_B['Before Corpus'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before List of Likes\"] = df_noName_B['Before List of Likes'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before List of Retweets\"] = df_noName_B['Before List of Retweets'].apply(ast.literal_eval)\n",
    "\n",
    "#Explode all three columns\n",
    "df_noName_A = df_noName_A.explode(['After Corpus', 'After List of Likes', 'After List of Retweets']).reset_index(drop=True)\n",
    "\n",
    "df_noName_B = df_noName_B.explode(['Before Corpus', 'Before List of Likes', 'Before List of Retweets']).reset_index(drop=True)\n",
    "\n",
    "#Remove any potential duplication in tweets (because of multiple scraping sessions)\n",
    "def remove_duplicate_rows(df, columns_to_check):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows from a DataFrame, keeping only the latest instance.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    columns_to_check (list): A list of column names to check for duplicates.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with duplicate rows removed.\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by the columns to check, in descending order\n",
    "    df = df.sort_values(by=columns_to_check, ascending=False)\n",
    "    \n",
    "    # Drop duplicate rows, keeping the first occurrence\n",
    "    df = df.drop_duplicates(subset=columns_to_check, keep='first')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_noName_A = remove_duplicate_rows(df_noName_A, \"After Corpus\")\n",
    "\n",
    "df_noName_B = remove_duplicate_rows(df_noName_B, \"Before Corpus\")\n",
    "\n",
    "\n",
    "#Exporting the DF to csv\n",
    "df_noName_A.to_csv('Cleaned Data/After_NN_Cleaned.csv', index=False) \n",
    "df_noName_B.to_csv('Cleaned Data/Before_NN_Cleaned.csv', index=False) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
