{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff4fd40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen  \n",
    "from tqdm import tqdm\n",
    "from lxml import html\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "# from screeninfo import get_monitors\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import ast\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe0483",
   "metadata": {},
   "source": [
    "# US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cef141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of followers to process: 11\n"
     ]
    }
   ],
   "source": [
    "#replace as needed\n",
    "folder_name = \"Supplementary Materials\"\n",
    "followers_path = os.path.join(folder_name, \"followers_US.txt\")\n",
    "completed_path = os.path.join(folder_name, \"completed_accounts\")\n",
    "\n",
    "followers_US = []\n",
    "# with open(r'''X\\followers_US.txt''', 'r') as f: # PC\n",
    "with open(followers_path,'r') as f: #List of accounts from raw followers list\n",
    "    for line in f:\n",
    "        if \"@\" in line:\n",
    "            follower = line.strip()[1:]\n",
    "            if follower not in followers_US:\n",
    "                # print(follower)\n",
    "                followers_US.append(follower)\n",
    "f.close()\n",
    "\n",
    "# with open(completed_path, 'r') as f: #Get list of accounts that are completed\n",
    "#     for line in f:\n",
    "#         if line.startswith('total'):\n",
    "#             completed_list = ast.literal_eval(line[8:])\n",
    "\n",
    "#Filter out the ones that are completed\n",
    "# followers_US_set = set(followers_US)\n",
    "# followers_US = [f for f in followers_US_set if f not in completed_list]\n",
    "\n",
    "# print(followers_US)\n",
    "followers_US = followers_US[64:]\n",
    "\n",
    "print(f\"Number of followers to process: {len(followers_US)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3565ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dict_US = {}\n",
    "\n",
    "# Function to check if the Fetch More button is present\n",
    "def is_element_present(driver, xpath):\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, xpath)\n",
    "        return element.is_displayed()\n",
    "    except NoSuchElementException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c11ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome()\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "driver.get('https://twitter.com/i/flow/login')\n",
    "wait = WebDriverWait(driver, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f177a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log in\n",
    "\n",
    "# Username\n",
    "username = wait.until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'input[autocomplete=username]'))\n",
    ")\n",
    "username.send_keys(\"blaketrn@udel.edu\")\n",
    "time.sleep(3)\n",
    "login_button = wait.until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, '[role=button].r-13qz1uu'))\n",
    ")\n",
    "login_button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "try: \n",
    "    # Password\n",
    "    password = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, '[type=password]'))\n",
    "    )\n",
    "    password.send_keys(\"Idontevenknow1!\")\n",
    "    time.sleep(3)\n",
    "    login_button = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, '[data-testid*=Login_Button]'))\n",
    "    )\n",
    "    login_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "except: # if we get an error\n",
    "    username = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-testid*=ocfEnterTextTextInput]\"))\n",
    "    )\n",
    "    username.send_keys(\"HaHoangNha55719\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    next_button = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-testid*=ocfEnterTextNextButton]\"))\n",
    "    )\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    password = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"[name*=password]\"))\n",
    "    )\n",
    "    password.send_keys(\"Idontevenknow1!\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    login_button = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-testid*=LoginForm_Login_Button]\"))\n",
    "    )\n",
    "    login_button.click()\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70948d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maryltrump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [01:06<11:03, 66.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JoJoFromJerz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [01:49<07:56, 52.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DineshDSouza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [02:34<06:33, 49.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbongino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [03:13<05:16, 45.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Accounts passed, sleeping for 5 minutes.\n",
      "TheLeoTerrell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5/11 [08:58<15:19, 153.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donaldjtrumpjr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [10:02<10:14, 122.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diamondandsilk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [10:52<06:35, 99.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spiritofho\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8/11 [11:37<04:05, 81.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MollyJongFast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [12:23<02:21, 70.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Accounts passed, sleeping for 5 minutes.\n",
      "FiorellaIsabelM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [18:12<02:36, 156.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaronjmate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [18:58<00:00, 103.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprocessed accounts for this run:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "keyword1 = \"(Gaza* OR Israel* OR (West Bank) OR (Tel Aviv) OR (Tel Aviv-Yafo) OR Bedouin* OR Palestin* OR Middle OR East* OR Middle OR Eastern OR Jew* OR rabbi OR Muslim* OR Islam* OR Jihad OR Antisemiti* OR Zionis* OR IDF)\"\n",
    "keyword2 = \"(IOF OR Hamas OR Massacre OR Genocide OR Ceasefire OR Terroris* OR Netanyahu OR Histadrut OR Haniyeh OR Yahya OR Sinwar OR Fatah OR Mohammed OR Deif OR Rafah OR Khan OR Younis OR Ben-Gvir OR Abbas OR Gallant)\"\n",
    "hashtags = \"(# OR #IsraelPalestineWar OR #IsraelGazaWar OR #Gazabombing OR #CeasefireNOW OR #FreePalestine OR #StrikeForGaza OR #Gazagenocide)\"\n",
    "until = \"2023-10-06\"\n",
    "since = \"2022-10-07\"\n",
    "\n",
    "unprocessed = []\n",
    "\n",
    "for profile in tqdm(followers_US):\n",
    "    if count%5 == 0:\n",
    "        print(\"5 Accounts passed, sleeping for 5 minutes.\")\n",
    "        time.sleep(300)\n",
    "    \n",
    "    if profile not in tweets_dict_US.keys():\n",
    "        print(profile)\n",
    "\n",
    "        tweets_dict_US[profile] = []\n",
    "\n",
    "        ### Begin scrape\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Search\n",
    "        search_button = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '[aria-label=\"Search and explore\"]'))\n",
    "        )\n",
    "        search_button.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        search_bar = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '[aria-label=\"Search\"]'))\n",
    "        )\n",
    "        search_bar.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        for i in range(2): \n",
    "            search_query = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '[aria-label=\"Search query\"]')))\n",
    "\n",
    "            # Advanced search query\n",
    "            if i == 0:\n",
    "                search_query.send_keys(f'{keyword1} {hashtags} (from:{profile}) min_faves:1000 until:{until} since:{since} -filter:links -filter:replies')\n",
    "            if i == 1:\n",
    "                search_query.send_keys([Keys.BACKSPACE]*1000)\n",
    "                search_query.send_keys(f'{keyword2} {hashtags} (from:{profile}) min_faves:1000 until:{until} since:{since} -filter:links -filter:replies')\n",
    "\n",
    "            search_query.send_keys(Keys.RETURN)\n",
    "            time.sleep(6)\n",
    "            \n",
    "            # Scroll until you cannot scroll anymore\n",
    "            reached_page_end = False\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            retry_xpath = \"//button[@role='button' and @type='button']//span[text()='Retry']\"\n",
    "            # random.randrange(10, 15)\n",
    "            if (is_element_present(driver, retry_xpath)):\n",
    "                try:\n",
    "                    print(f'{profile} - {count} - Retry button appeared.')\n",
    "                    unprocessed.append(profile)\n",
    "                    for i in range(5):\n",
    "                        search_button = wait.until(EC.element_to_be_clickable((By.XPATH, retry_xpath)))\n",
    "                        search_button.click()\n",
    "                    time.sleep(100) \n",
    "                except:\n",
    "                    print(f\"{profile} - Failed to click Retry\")\n",
    "\n",
    "            while not reached_page_end:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")   \n",
    "                time.sleep(6)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if last_height == new_height:\n",
    "                    reached_page_end = True\n",
    "                else:\n",
    "                    last_height = new_height\n",
    "            try:\n",
    "                # Select the home timeline div\n",
    "                search_results = driver.find_element(By.CSS_SELECTOR, '[aria-label=\"Timeline: Search timeline\"]')\n",
    "                # Just get all the HTML, will parse later\n",
    "                tweets_listed = search_results.get_attribute('innerHTML')\n",
    "                time.sleep(3)\n",
    "\n",
    "                # Append to dict\n",
    "                tweets_dict_US[profile].append(tweets_listed)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    count+=1\n",
    "\n",
    "print(\"Unprocessed accounts for this run:\")\n",
    "for profile in unprocessed:\n",
    "    print(f\"@{profile}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97adfdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7de5e024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['maryltrump', 'JoJoFromJerz', 'DineshDSouza', 'dbongino', 'TheLeoTerrell', 'donaldjtrumpjr', 'diamondandsilk', 'spiritofho', 'MollyJongFast', 'FiorellaIsabelM', 'aaronjmate'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dict_US.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3d896ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['maryltrump', 'JoJoFromJerz', 'DineshDSouza', 'dbongino', 'TheLeoTerrell', 'donaldjtrumpjr', 'diamondandsilk', 'spiritofho', 'MollyJongFast', 'FiorellaIsabelM', 'aaronjmate'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dict_US_cleaned = {}\n",
    "    \n",
    "for key, value in tweets_dict_US.items():\n",
    "    if key not in tweets_dict_US_cleaned.keys():\n",
    "        tweets_dict_US_cleaned[key] = []\n",
    "        for v in value:\n",
    "            soup = BeautifulSoup(v, 'html.parser')\n",
    "            tweets = soup.find_all(attrs={\"data-testid\": \"tweetText\"})\n",
    "            for tweet in tweets:\n",
    "                tweet_text = tweet.get_text(strip=True)\n",
    "                tweets_dict_US_cleaned[key].append(tweet_text)\n",
    "\n",
    "tweets_dict_US_cleaned.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a959259",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder = os.path.join(\"Raw Data\", \"Before\")\n",
    "raw_json = os.path.join(raw_data_folder, f\"US_tweets_{until}_{since}.json\")\n",
    "cleaned_json = os.path.join(raw_data_folder, f\"US_tweets_cleaned_{until}_{since}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "862b1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(raw_json, 'w') as file:\n",
    "    json.dump(tweets_dict_US, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c5ac73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cleaned_json, 'w') as file:\n",
    "    json.dump(tweets_dict_US_cleaned, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
