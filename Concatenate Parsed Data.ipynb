{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field  # Import field\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove tweets talking about the train derailment in East Palestine, OH\n",
    "def not_palestine_OH(text: str, window_size: int = 50) -> bool:\n",
    "    \"\"\"\n",
    "    Check if keywords appear near each other in text.\n",
    "    Returns True if at least two keywords are found within window_size words.\n",
    "    \"\"\"\n",
    "    keywords = [\"east palestine\", \"oh\", \"train\", \"derailment\", \"e. palestine\"]\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = text.split()\n",
    "    for i in range(len(words)):\n",
    "        window = ' '.join(words[i:i + window_size])\n",
    "        found = sum(1 for k in keywords if re.search(r'\\b' + re.escape(k) + r'\\b', window))\n",
    "        if found >= 1:\n",
    "            return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "#Remove any potential duplication in tweets (because of multiple scraping sessions)\n",
    "def remove_duplicate_rows(df, columns_to_check):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows from a DataFrame, keeping only the latest instance.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    columns_to_check (list): A list of column names to check for duplicates.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with duplicate rows removed.\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by the columns to check, in descending order\n",
    "    df = df.sort_values(by=columns_to_check, ascending=False)\n",
    "    \n",
    "    # Drop duplicate rows, keeping the first occurrence\n",
    "    df = df.drop_duplicates(subset=columns_to_check, keep='first')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: CONCATENATE ALL FILES IN PARSED DATA FOLDER\n",
    "The output will be the Pre-processing.csv, which will be used to Step 2 below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Influencer: SabbySabs2\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: MsLaToshaBrown\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: RonFilipkowski\n",
      "Before corpus size: 3\n",
      "After corpus size: 20\n",
      "\n",
      "Influencer: KyleKulinski\n",
      "Before corpus size: 0\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: funder\n",
      "Before corpus size: 0\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: mmpadellan\n",
      "Before corpus size: 0\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: krystalball\n",
      "Before corpus size: 0\n",
      "After corpus size: 8\n",
      "\n",
      "Influencer: SteveSchmidtSES\n",
      "Before corpus size: 4\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: robreiner\n",
      "Before corpus size: 1\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: marceelias\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TheRickWilson\n",
      "Before corpus size: 5\n",
      "After corpus size: 8\n",
      "\n",
      "Influencer: davidsirota\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: TristanSnell\n",
      "Before corpus size: 0\n",
      "After corpus size: 16\n",
      "\n",
      "Influencer: KyleClark\n",
      "Before corpus size: 1\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: PatrickSvitek\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: evanasmith\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BarbMcQuade\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: JohnArchibald\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: natsechobbyist\n",
      "Before corpus size: 1\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: davidhogg111\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: anthonyzenkus\n",
      "Before corpus size: 2\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: briebriejoy\n",
      "Before corpus size: 5\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: fred_guttenberg\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: JordanChariton\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: kylegriffin1\n",
      "Before corpus size: 2\n",
      "After corpus size: 16\n",
      "\n",
      "Influencer: itsJeffTiedrich\n",
      "Before corpus size: 4\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: bluestein\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: Josh_Moon\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: WarOnDumb\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: ProudSocialist\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: maryltrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: JoJoFromJerz\n",
      "Before corpus size: 3\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: MollyJongFast\n",
      "Before corpus size: 4\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: aaronjmate\n",
      "Before corpus size: 10\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: checkmatestate\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: jimmy_dore\n",
      "Before corpus size: 2\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: bshelburne\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: LeeCamp\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: SocialistMMA\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: spiritofho\n",
      "Before corpus size: 3\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: FiorellaIsabelM\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: RealSpikeCohen\n",
      "Before corpus size: 2\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: ComicDaveSmith\n",
      "Before corpus size: 9\n",
      "After corpus size: 12\n",
      "\n",
      "Influencer: HannahDCox\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BillOReilly\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: ThomasEWoods\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: FreemansMind96\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: DavidAFrench\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: gtconway3d\n",
      "Before corpus size: 0\n",
      "After corpus size: 9\n",
      "\n",
      "Influencer: spann\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: Jaybefaunt\n",
      "Before corpus size: 0\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: BernardKerik\n",
      "Before corpus size: 3\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: jeff_poor\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TomFitton\n",
      "Before corpus size: 5\n",
      "After corpus size: 4\n",
      "\n",
      "Influencer: brad_polumbo\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: IngrahamAngle\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: seanhannity\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: charliekirk11\n",
      "Before corpus size: 0\n",
      "After corpus size: 13\n",
      "\n",
      "Influencer: TuckerCarlson\n",
      "Before corpus size: 0\n",
      "After corpus size: 6\n",
      "\n",
      "Influencer: AnnCoulter\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: EricTrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: LaraLeaTrump\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: PatTheSocialist\n",
      "Before corpus size: 0\n",
      "After corpus size: 9\n",
      "\n",
      "Influencer: NancyAFrench\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: donwinslow\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: BobMurphyEcon\n",
      "Before corpus size: 0\n",
      "After corpus size: 2\n",
      "\n",
      "Influencer: benshapiro\n",
      "Before corpus size: 12\n",
      "After corpus size: 33\n",
      "\n",
      "Influencer: elonmusk\n",
      "Before corpus size: 7\n",
      "After corpus size: 13\n",
      "\n",
      "Influencer: SarcasmStardust\n",
      "Before corpus size: 1\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: toddcstacy\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: DineshDSouza\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: dbongino\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: TheLeoTerrell\n",
      "Before corpus size: 0\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: donaldjtrumpjr\n",
      "Before corpus size: 3\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: diamondandsilk\n",
      "Before corpus size: 0\n",
      "After corpus size: 0\n",
      "\n",
      "Influencer: michaelmalice\n",
      "Before corpus size: 1\n",
      "After corpus size: 7\n",
      "\n",
      "Influencer: tomilahren\n",
      "Before corpus size: 1\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: glennbeck\n",
      "Before corpus size: 1\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: coachbrucepearl\n",
      "Before corpus size: 2\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: bennyjohnson\n",
      "Before corpus size: 0\n",
      "After corpus size: 5\n",
      "\n",
      "Influencer: marklevinshow\n",
      "Before corpus size: 1\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: ksorbs\n",
      "Before corpus size: 1\n",
      "After corpus size: 1\n",
      "\n",
      "Influencer: atensnut\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: scottpresler\n",
      "Before corpus size: 0\n",
      "After corpus size: 7\n",
      "\n",
      "Influencer: pnjaban\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n",
      "\n",
      "Influencer: hodgetwins\n",
      "Before corpus size: 0\n",
      "After corpus size: 3\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Influencer:\n",
    "    name: str\n",
    "    affiliation: str\n",
    "    no_followers: int = 0\n",
    "    before_corpus: list = field(default_factory=list) \n",
    "    before_dates: list = field(default_factory=list)\n",
    "    before_likes: list = field(default_factory=list)\n",
    "    before_retweets: list = field(default_factory=list)\n",
    "    before_replies: list = field(default_factory=list)\n",
    "    before_views: list = field(default_factory=list)\n",
    "    after_corpus: list = field(default_factory=list)\n",
    "    after_dates: list = field(default_factory=list)\n",
    "    after_likes: list = field(default_factory=list)\n",
    "    after_retweets: list = field(default_factory=list)\n",
    "    after_replies: list = field(default_factory=list)\n",
    "    after_views: list = field(default_factory=list)\n",
    "\n",
    "data = []\n",
    "account_list = []\n",
    "\n",
    "#Loading File paths\n",
    "supplementary_folder = \"Supplementary Materials\"\n",
    "influencers_path = os.path.join(supplementary_folder, \"Followers List & Categories - Accounts Kept.csv\")\n",
    "\n",
    "#Population the data file with initial data of the available influencers\n",
    "with open(influencers_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader) #skip header\n",
    "    for line in reader:\n",
    "        name = line[0]\n",
    "        account_list.append(name[1:]) #Creating a list of influencers account names\n",
    "\n",
    "        affiliation = line[1]\n",
    "        followers = line[2]\n",
    "        if affiliation or followers:\n",
    "            data.append(Influencer(name[1:], affiliation, followers))\n",
    "\n",
    "parsed_before_folder = os.path.join(\"Parsed Data\", \"Before\")\n",
    "parsed_after_folder = os.path.join(\"Parsed Data\", \"After\")\n",
    "\n",
    "before_files = [f for f in os.listdir(parsed_before_folder) if f.endswith('.csv')] #Getting all before files\n",
    "after_files = [f for f in os.listdir(parsed_after_folder) if f.endswith('.csv')] #Getting all after files\n",
    "\n",
    "def getting_values(files: list, path: str, after: bool):\n",
    "    for f in files:\n",
    "        with open(f\"{path}/{f}\", 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            next(reader) #skip header\n",
    "            \n",
    "            for line in reader:\n",
    "                if not line:  # Skip empty lines\n",
    "                    continue\n",
    "                if line[0] == \"|RUN STATISTICS|\": # End of file, move on to next file\n",
    "                    break\n",
    "            \n",
    "                name = line[0].strip() if line else \"\"\n",
    "                tweet = line[2].strip()\n",
    "                date = line[1]\n",
    "                like = int(line[3].strip())\n",
    "                retweet = int(line[4].strip())\n",
    "                reply = int(line[5].strip())\n",
    "                view = int(line[6].strip())\n",
    "\n",
    "                for i in data:\n",
    "                    if name == i.name:\n",
    "                        if after and (tweet not in c for c in i.after_corpus) and like >1000 and not_palestine_OH(tweet):\n",
    "                                i.after_corpus.append(tweet)\n",
    "                                i.after_dates.append(date)\n",
    "                                i.after_likes.append(like)\n",
    "                                i.after_retweets.append(retweet)\n",
    "                                i.after_replies.append(reply)\n",
    "                                i.after_views.append(view)\n",
    "                                \n",
    "                        else:\n",
    "                            if (tweet not in c for c in i.before_corpus) and like > 1000 and not_palestine_OH(tweet):\n",
    "                                i.before_corpus.append(tweet)\n",
    "                                i.before_dates.append(date)\n",
    "                                i.before_likes.append(like)\n",
    "                                i.before_retweets.append(retweet)\n",
    "                                i.before_replies.append(reply)\n",
    "                                i.before_views.append(view)\n",
    "\n",
    "getting_values(before_files, parsed_before_folder, False)\n",
    "getting_values(after_files, parsed_after_folder, True)\n",
    "\n",
    "# Check results for each influencer\n",
    "for i in data:\n",
    "    print(f\"\\nInfluencer: {i.name}\")\n",
    "    print(f\"Before corpus size: {len(i.before_corpus)}\")\n",
    "    # print(f\"Before likes list: {(i.before_likes)}\")\n",
    "    # print(f\"Before retweets list: {(i.before_retweets)}\")\n",
    "    print(f\"After corpus size: {len(i.after_corpus)}\")\n",
    "    # print(f\"After likes list: {(i.after_likes)}\")\n",
    "    # print(f\"After retweets list: {(i.after_retweets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Supplementary Materials/Pre-processing.csv\", 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Name','Affiliation', 'Number of Followers', \n",
    "                         \"Before Dates\", \"Before Corpus\", \"Before Likes\", \"Before Retweets\", \n",
    "                         \"Before Replies\", \"Before Views\",\n",
    "                         \"After Dates\", \"After Corpus\", \"After Likes\", \"After Retweets\",\n",
    "                         \"After Replies\", \"After Views\"])\n",
    "    \n",
    "        for i in data:\n",
    "            if i.before_corpus and i.after_corpus:\n",
    "                writer.writerow([i.name, i.affiliation, i.no_followers, \n",
    "                                 i.before_dates, i.before_corpus, i.before_likes, \n",
    "                                 i.before_retweets, i.before_replies, i.before_views, \n",
    "                                 i.after_dates, i.after_corpus, i.after_likes, \n",
    "                                 i.after_retweets, i.after_replies, i.after_views])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 2: SUBJECT ANONYMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Number of Followers</th>\n",
       "      <th>Before Dates</th>\n",
       "      <th>Before Corpus</th>\n",
       "      <th>Before Likes</th>\n",
       "      <th>Before Retweets</th>\n",
       "      <th>Before Replies</th>\n",
       "      <th>Before Views</th>\n",
       "      <th>After Dates</th>\n",
       "      <th>After Corpus</th>\n",
       "      <th>After Likes</th>\n",
       "      <th>After Retweets</th>\n",
       "      <th>After Replies</th>\n",
       "      <th>After Views</th>\n",
       "      <th>Subject ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RonFilipkowski</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>['October 19, 2022 10:01 PM', 'October 19, 202...</td>\n",
       "      <td>['Dershowitz said Trump asked him at dinner wh...</td>\n",
       "      <td>[1337, 7377, 7417]</td>\n",
       "      <td>[303, 1882, 1888]</td>\n",
       "      <td>[724, 481, 481]</td>\n",
       "      <td>[554681, 1786934, 1786905]</td>\n",
       "      <td>['July 28, 2024 03:38 PM', 'July 25, 2024 04:5...</td>\n",
       "      <td>['How odd for Trump to Blame America First for...</td>\n",
       "      <td>[1520, 2370, 1244, 1440, 2369, 34866, 3056, 15...</td>\n",
       "      <td>[363, 703, 229, 476, 702, 18715, 597, 363, 477...</td>\n",
       "      <td>[103, 253, 46, 1016, 252, 4802, 306, 103, 1015...</td>\n",
       "      <td>[66505, 58445, 44492, 159444, 58467, 10733427,...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SteveSchmidtSES</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>['October 16, 2022 04:11 PM', 'January 05, 202...</td>\n",
       "      <td>['A direct threat against American Jews by a d...</td>\n",
       "      <td>[1223, 1420, 1420, 1238]</td>\n",
       "      <td>[251, 459, 459, 254]</td>\n",
       "      <td>[92, 90, 90, 92]</td>\n",
       "      <td>[101802, 122221, 122221, 101793]</td>\n",
       "      <td>['October 24, 2023 06:08 PM', 'October 24, 202...</td>\n",
       "      <td>['\"The corruption of one man in Israel has bro...</td>\n",
       "      <td>[4262, 4259, 13223, 4230]</td>\n",
       "      <td>[1588, 1586, 4037, 1580]</td>\n",
       "      <td>[314, 314, 810, 316]</td>\n",
       "      <td>[228271, 228247, 1048489, 228291]</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TheRickWilson</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>['April 17, 2023 03:16 PM', 'November 01, 2022...</td>\n",
       "      <td>['The purpose of terrorism is to terrorize.', ...</td>\n",
       "      <td>[6283, 6283, 6242, 6289, 3502]</td>\n",
       "      <td>[732, 732, 730, 732, 460]</td>\n",
       "      <td>[154, 154, 153, 154, 49]</td>\n",
       "      <td>[233147, 233147, 233147, 233147, 137897]</td>\n",
       "      <td>['July 31, 2024 01:21 PM', 'September 14, 2024...</td>\n",
       "      <td>['If you think its bad thing that the leaders ...</td>\n",
       "      <td>[3334, 1634, 2311, 3333, 1633, 2308, 3309, 3046]</td>\n",
       "      <td>[315, 304, 218, 317, 304, 218, 316, 658]</td>\n",
       "      <td>[90, 47, 29, 90, 47, 29, 90, 265]</td>\n",
       "      <td>[77274, 95900, 48497, 77287, 95932, 48501, 773...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natsechobbyist</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>477600.0</td>\n",
       "      <td>['October 16, 2022 02:59 PM']</td>\n",
       "      <td>['My daughter is at Hebrew school this morning...</td>\n",
       "      <td>[3510]</td>\n",
       "      <td>[83]</td>\n",
       "      <td>[166]</td>\n",
       "      <td>[62356]</td>\n",
       "      <td>['August 22, 2024 07:35 PM', 'October 10, 2023...</td>\n",
       "      <td>['I despise Bibi.  I don’t think it’s a genoci...</td>\n",
       "      <td>[1568, 2340, 4235]</td>\n",
       "      <td>[595, 540, 683]</td>\n",
       "      <td>[4, 39, 747]</td>\n",
       "      <td>[41068, 154415, 401663]</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anthonyzenkus</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>88800.0</td>\n",
       "      <td>['November 24, 2022 02:55 PM', 'November 24, 2...</td>\n",
       "      <td>['You cannot say you care about women in Iran ...</td>\n",
       "      <td>[1471, 1464]</td>\n",
       "      <td>[642, 642]</td>\n",
       "      <td>[49, 49]</td>\n",
       "      <td>[45843, 45878]</td>\n",
       "      <td>['April 21, 2024 10:15 PM', 'May 15, 2024 08:4...</td>\n",
       "      <td>['They release this the day we find out that I...</td>\n",
       "      <td>[1739, 1505, 1305, 5419, 1016, 1008]</td>\n",
       "      <td>[190, 619, 488, 2199, 741, 733]</td>\n",
       "      <td>[68, 44, 43, 289, 52, 52]</td>\n",
       "      <td>[50019, 31610, 16921, 101954, 30287, 30333]</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name       Affiliation  Number of Followers  \\\n",
       "0   RonFilipkowski  Democratic Party            1000000.0   \n",
       "1  SteveSchmidtSES  Democratic Party            1500000.0   \n",
       "2    TheRickWilson  Democratic Party            1600000.0   \n",
       "3   natsechobbyist  Democratic Party             477600.0   \n",
       "4    anthonyzenkus  Democratic Party              88800.0   \n",
       "\n",
       "                                        Before Dates  \\\n",
       "0  ['October 19, 2022 10:01 PM', 'October 19, 202...   \n",
       "1  ['October 16, 2022 04:11 PM', 'January 05, 202...   \n",
       "2  ['April 17, 2023 03:16 PM', 'November 01, 2022...   \n",
       "3                      ['October 16, 2022 02:59 PM']   \n",
       "4  ['November 24, 2022 02:55 PM', 'November 24, 2...   \n",
       "\n",
       "                                       Before Corpus  \\\n",
       "0  ['Dershowitz said Trump asked him at dinner wh...   \n",
       "1  ['A direct threat against American Jews by a d...   \n",
       "2  ['The purpose of terrorism is to terrorize.', ...   \n",
       "3  ['My daughter is at Hebrew school this morning...   \n",
       "4  ['You cannot say you care about women in Iran ...   \n",
       "\n",
       "                     Before Likes            Before Retweets  \\\n",
       "0              [1337, 7377, 7417]          [303, 1882, 1888]   \n",
       "1        [1223, 1420, 1420, 1238]       [251, 459, 459, 254]   \n",
       "2  [6283, 6283, 6242, 6289, 3502]  [732, 732, 730, 732, 460]   \n",
       "3                          [3510]                       [83]   \n",
       "4                    [1471, 1464]                 [642, 642]   \n",
       "\n",
       "             Before Replies                              Before Views  \\\n",
       "0           [724, 481, 481]                [554681, 1786934, 1786905]   \n",
       "1          [92, 90, 90, 92]          [101802, 122221, 122221, 101793]   \n",
       "2  [154, 154, 153, 154, 49]  [233147, 233147, 233147, 233147, 137897]   \n",
       "3                     [166]                                   [62356]   \n",
       "4                  [49, 49]                            [45843, 45878]   \n",
       "\n",
       "                                         After Dates  \\\n",
       "0  ['July 28, 2024 03:38 PM', 'July 25, 2024 04:5...   \n",
       "1  ['October 24, 2023 06:08 PM', 'October 24, 202...   \n",
       "2  ['July 31, 2024 01:21 PM', 'September 14, 2024...   \n",
       "3  ['August 22, 2024 07:35 PM', 'October 10, 2023...   \n",
       "4  ['April 21, 2024 10:15 PM', 'May 15, 2024 08:4...   \n",
       "\n",
       "                                        After Corpus  \\\n",
       "0  ['How odd for Trump to Blame America First for...   \n",
       "1  ['\"The corruption of one man in Israel has bro...   \n",
       "2  ['If you think its bad thing that the leaders ...   \n",
       "3  ['I despise Bibi.  I don’t think it’s a genoci...   \n",
       "4  ['They release this the day we find out that I...   \n",
       "\n",
       "                                         After Likes  \\\n",
       "0  [1520, 2370, 1244, 1440, 2369, 34866, 3056, 15...   \n",
       "1                          [4262, 4259, 13223, 4230]   \n",
       "2   [3334, 1634, 2311, 3333, 1633, 2308, 3309, 3046]   \n",
       "3                                 [1568, 2340, 4235]   \n",
       "4               [1739, 1505, 1305, 5419, 1016, 1008]   \n",
       "\n",
       "                                      After Retweets  \\\n",
       "0  [363, 703, 229, 476, 702, 18715, 597, 363, 477...   \n",
       "1                           [1588, 1586, 4037, 1580]   \n",
       "2           [315, 304, 218, 317, 304, 218, 316, 658]   \n",
       "3                                    [595, 540, 683]   \n",
       "4                    [190, 619, 488, 2199, 741, 733]   \n",
       "\n",
       "                                       After Replies  \\\n",
       "0  [103, 253, 46, 1016, 252, 4802, 306, 103, 1015...   \n",
       "1                               [314, 314, 810, 316]   \n",
       "2                  [90, 47, 29, 90, 47, 29, 90, 265]   \n",
       "3                                       [4, 39, 747]   \n",
       "4                          [68, 44, 43, 289, 52, 52]   \n",
       "\n",
       "                                         After Views  Subject ID  \n",
       "0  [66505, 58445, 44492, 159444, 58467, 10733427,...          39  \n",
       "1                  [228271, 228247, 1048489, 228291]          92  \n",
       "2  [77274, 95900, 48497, 77287, 95932, 48501, 773...          60  \n",
       "3                            [41068, 154415, 401663]          77  \n",
       "4        [50019, 31610, 16921, 101954, 30287, 30333]          63  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Supplementary Materials/Pre-processing.csv\")\n",
    "\n",
    "# Generate random IDs for all subjects - uncomment to generate initial Ledger file\n",
    "# random_ids = random.sample(range(10, 99), len(df))  # Modified to match DataFrame length\n",
    "\n",
    "# # Assign random IDs directly to the Subject ID column\n",
    "# df[\"Subject ID\"] = random_ids\n",
    "\n",
    "# #Use to create new ledger file\n",
    "# df_nametoID = df[[\"Name\", \"Subject ID\"]]\n",
    "# df_nametoID.head()\n",
    "# df_nametoID.to_csv('Supplementary Materials/Subject Ledger.csv', index=False) \n",
    "\n",
    "\n",
    "# Load in existing Ledger file\n",
    "ledger = pd.read_csv(\"Supplementary Materials/Subject Ledger.csv\") \n",
    "ledger_records = ledger.to_dict(orient='records')\n",
    "\n",
    "ledger_dict = {}\n",
    "\n",
    "for l in ledger_records:\n",
    "    ledger_dict[l['Name']] = l['Subject ID']\n",
    "\n",
    "df[\"Subject ID\"] = df[\"Name\"].map(ledger_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noName = df[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \n",
    "                \"Before Dates\", \"Before Corpus\", \"Before Likes\", \"Before Retweets\", \"Before Replies\", \"Before Views\",\n",
    "                \"After Dates\", \"After Corpus\", \"After Likes\", \"After Retweets\", \"After Replies\", \"After Views\"]]\n",
    "\n",
    "df_noName.to_csv(\"Cleaned Data/All_NN_Cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTRAST CODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noName[\"Contrast\"] = 0.0\n",
    "\n",
    "affiliation_dict = {\n",
    "    \"Republican Party\": -0.5,\n",
    "    \"Democratic Party\": 0.5\n",
    "    # \"Other\": 0.0\n",
    "}\n",
    "\n",
    "df_noName[\"Contrast\"] = df_noName[\"Affiliation\"].map(affiliation_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before\n",
    "df_noName_B = df_noName[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Before Dates\", \"Before Corpus\", \"Before Likes\", \"Before Retweets\", \"Before Replies\", \"Before Views\", \"Contrast\"]]\n",
    "#After\n",
    "df_noName_A = df_noName[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"After Dates\", \"After Corpus\", \"After Likes\", \"After Retweets\", \"After Replies\", \"After Views\", \"Contrast\"]]\n",
    "\n",
    "#Convert strings representation of list into list\n",
    "df_noName_A.loc[:, \"After Corpus\"] = df_noName_A['After Corpus'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After Dates\"] = df_noName_A['After Dates'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After Likes\"] = df_noName_A['After Likes'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After Retweets\"] = df_noName_A['After Retweets'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After Replies\"] = df_noName_A['After Replies'].apply(ast.literal_eval)\n",
    "df_noName_A.loc[:, \"After Views\"] = df_noName_A['After Views'].apply(ast.literal_eval)\n",
    "\n",
    "df_noName_B.loc[:, \"Before Corpus\"] = df_noName_B['Before Corpus'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before Dates\"] = df_noName_B['Before Dates'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before Likes\"] = df_noName_B['Before Likes'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before Retweets\"] = df_noName_B['Before Retweets'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before Replies\"] = df_noName_B['Before Replies'].apply(ast.literal_eval)\n",
    "df_noName_B.loc[:, \"Before Views\"] = df_noName_B['Before Views'].apply(ast.literal_eval)\n",
    "\n",
    "#Explode all three columns\n",
    "df_noName_A = df_noName_A.explode([\"After Dates\", 'After Corpus', 'After Likes', 'After Retweets',\"After Replies\", \"After Views\"]).reset_index(drop=True)\n",
    "df_noName_B = df_noName_B.explode([\"Before Dates\", 'Before Corpus', 'Before Likes', 'Before Retweets', \"Before Replies\", \"Before Views\"]).reset_index(drop=True)\n",
    "\n",
    "df_noName_A = remove_duplicate_rows(df_noName_A, \"After Corpus\")\n",
    "df_noName_B = remove_duplicate_rows(df_noName_B, \"Before Corpus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate random IDs for all tweets - uncomment to generate initial Ledger file\n",
    "# tweets_random_ids = random.sample(range(100, 999), len(df_noName_A) + len(df_noName_B))  # Modified to match DataFrame length\n",
    "\n",
    "# # Assign random IDs directly to the Subject ID column\n",
    "# df_noName_A[\"Tweet ID\"] = tweets_random_ids[:len(df_noName_A)]\n",
    "# df_noName_B[\"Tweet ID\"] = tweets_random_ids[len(df_noName_A):]\n",
    "\n",
    "# # Select and rename columns to have a common column name \"Corpus\" \n",
    "# df_tweet_before = df_noName_B[[\"Tweet ID\", \"Before Corpus\"]].rename(columns={\"Before Corpus\": \"Corpus\"}) \n",
    "# df_tweet_after = df_noName_A[[\"Tweet ID\", \"After Corpus\"]].rename(columns={\"After Corpus\": \"Corpus\"}) \n",
    "\n",
    "# # Add a new column to indicate the source of the corpus \n",
    "# df_tweet_before[\"Source\"] = \"Before\" \n",
    "# df_tweet_after[\"Source\"] = \"After\" \n",
    "\n",
    "# # Concatenate the DataFrames \n",
    "# df_tweet_ledger = pd.concat([df_tweet_before, df_tweet_after], ignore_index=True)\n",
    "# df_tweet_ledger.head()\n",
    "# df_tweet_ledger.to_csv('Supplementary Materials/Tweets Ledger.csv', index=False) #Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in existing Ledger file\n",
    "tweet_ledger = pd.read_csv(\"Supplementary Materials/Tweets Ledger.csv\") \n",
    "tweet_ledger_records = tweet_ledger.to_dict(orient='records')\n",
    "tweet_ledger_dict = {}\n",
    "\n",
    "for l in tweet_ledger_records:\n",
    "    tweet_ledger_dict[l['Corpus']] = l['Tweet ID']\n",
    "\n",
    "df_noName_A[\"Tweet ID\"] = df_noName_A[\"After Corpus\"].map(tweet_ledger_dict)\n",
    "df_noName_B[\"Tweet ID\"] = df_noName_B[\"Before Corpus\"].map(tweet_ledger_dict)\n",
    "\n",
    "# df_noName_B.head()\n",
    "\n",
    "#Reordering the columns\n",
    "df_noName_B = df_noName_B[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Tweet ID\", \"Contrast\", \"Before Dates\", \"Before Corpus\", \"Before Likes\", \"Before Retweets\", \"Before Replies\", \"Before Views\"]]\n",
    "df_noName_A = df_noName_A[[\"Subject ID\", \"Affiliation\", \"Number of Followers\", \"Tweet ID\", \"Contrast\", \"After Dates\", \"After Corpus\", \"After Likes\", \"After Retweets\", \"After Replies\", \"After Views\"]]\n",
    "\n",
    "#Exporting the DF to csv\n",
    "df_noName_A.to_csv('Cleaned Data/After_NN_Cleaned.csv', index=False) \n",
    "df_noName_B.to_csv('Cleaned Data/Before_NN_Cleaned.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|STATISTICS|\n",
      "Before Tweets: 64\n",
      "After Tweets: 154\n",
      "Number of Democratic Influencer: 13\n",
      "Number of Republican Influencer: 14\n",
      "Number of Democrats Tweets After: 67\n",
      "Number of Republican Tweets After: 87\n",
      "Number of Democrats Tweets Before: 30\n",
      "Number of Republican Tweets Before: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"|STATISTICS|\")\n",
    "print(f\"Before Tweets: {len(df_noName_B)}\")\n",
    "print(f\"After Tweets: {len(df_noName_A)}\")\n",
    "print(f\"Number of Democratic Influencer: {sum(df_noName['Affiliation'] == 'Democratic Party')}\")\n",
    "print(f\"Number of Republican Influencer: {sum(df_noName['Affiliation'] == 'Republican Party')}\")\n",
    "print(f\"Number of Democrats Tweets After: {sum(df_noName_A['Affiliation'] == 'Democratic Party')}\")\n",
    "print(f\"Number of Republican Tweets After: {sum(df_noName_A['Affiliation'] == 'Republican Party')}\")\n",
    "print(f\"Number of Democrats Tweets Before: {sum(df_noName_B['Affiliation'] == 'Democratic Party')}\")\n",
    "print(f\"Number of Republican Tweets Before: {sum(df_noName_B['Affiliation'] == 'Republican Party')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
