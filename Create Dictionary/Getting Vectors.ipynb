{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/yn_f16552qvcz999s7pwv5sm0000gn/T/ipykernel_7536/3408603504.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: Incompetence\n",
      "Processing category: Warm\n",
      "Processing category: Cold\n",
      "Processing category: Competence\n",
      "Processing category: Jews\n",
      "Processing category: Christians\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "       category           word  \\\n",
      "0  Incompetence      unnatural   \n",
      "1  Incompetence           back   \n",
      "2  Incompetence   uneconomical   \n",
      "3  Incompetence      dependent   \n",
      "4  Incompetence  unworkmanlike   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.21742886, 0.25219482, -0.08264218, 0.05514...  \n",
      "1  [-0.18149848, 0.13819107, -0.16554144, -0.0107...  \n",
      "2  [-0.9678343, 0.1915159, -0.53415775, 0.1020671...  \n",
      "3  [-0.19741559, 0.088816985, 0.06223922, 0.03611...  \n",
      "4  [-0.7659353, 0.08473118, -0.66141856, 0.282256...  \n",
      "\n",
      "Embedding shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "def get_bert_embedding(text, tokenizer, model):\n",
    "    \"\"\"Get BERT embedding for a single word/phrase.\"\"\"\n",
    "    # Add special tokens and convert to tensor\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized)\n",
    "    segments_ids = [1] * len(tokenized)\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    # Use [CLS] token embedding as sentence representation\n",
    "    token_embeddings = hidden_states[0]\n",
    "    return token_embeddings[0].numpy()  # Return the [CLS] token embedding\n",
    "\n",
    "def process_stereotype_dictionary(json_data):\n",
    "    # Load pre-trained model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    categories = []\n",
    "    words = []\n",
    "    embeddings = []\n",
    "    \n",
    "    # Process each category and its words\n",
    "    for category, word_list in json_data.items():\n",
    "        print(f\"Processing category: {category}\")\n",
    "        for word in word_list:\n",
    "            # Get embedding for the word\n",
    "            embedding = get_bert_embedding(word, tokenizer, model)\n",
    "            \n",
    "            # Append to lists\n",
    "            categories.append(category)\n",
    "            words.append(word)\n",
    "            embeddings.append(embedding)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'category': categories,\n",
    "        'word': words,\n",
    "        'embedding': embeddings\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load and process the data\n",
    "file_path = 'Stereotype_Dictionary.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    stereotype_dict = json.load(file)\n",
    "\n",
    "# Process the dictionary and get embeddings\n",
    "df = process_stereotype_dictionary(stereotype_dict)\n",
    "\n",
    "# Save to CSV (embeddings will be stored as string representation)\n",
    "df.to_csv('Stereotypes_word_embeddings.csv', index=False)\n",
    "\n",
    "# # Optional: Save to pickle to preserve numpy arrays\n",
    "# df.to_pickle('word_embeddings.pkl')\n",
    "\n",
    "# Print first few rows\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print embedding shape\n",
    "print(\"\\nEmbedding shape:\", df['embedding'].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the data\n",
    "file_path = 'Stereotype_Dictionary.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    stereotype_dict = json.load(file)\n",
    "\n",
    "# Process the dictionary and get embeddings\n",
    "df = process_stereotype_dictionary(stereotype_dict)\n",
    "\n",
    "# Save to CSV (embeddings will be stored as string representation)\n",
    "df.to_csv('Stereotypes_word_embeddings.csv', index=False)\n",
    "\n",
    "# # Optional: Save to pickle to preserve numpy arrays\n",
    "# df.to_pickle('word_embeddings.pkl')\n",
    "\n",
    "# Print first few rows\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print embedding shape\n",
    "print(\"\\nEmbedding shape:\", df['embedding'].iloc[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
